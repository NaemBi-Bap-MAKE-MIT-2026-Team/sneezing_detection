<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no" />
  <title>Sneeze Detector — Mic Sender</title>
  <style>
    *, *::before, *::after { box-sizing: border-box; margin: 0; padding: 0; }

    :root {
      --bg: #0f0f13;
      --card: #1a1a22;
      --border: #2e2e3e;
      --accent: #6c63ff;
      --accent-dim: #3d3880;
      --green: #3ddc84;
      --red: #ff5c5c;
      --yellow: #ffd166;
      --text: #e8e8f0;
      --muted: #888899;
      --radius: 14px;
      --font: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, sans-serif;
    }

    body {
      background: var(--bg);
      color: var(--text);
      font-family: var(--font);
      min-height: 100dvh;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 24px 16px 40px;
      gap: 20px;
    }

    h1 {
      font-size: 1.4rem;
      font-weight: 700;
      letter-spacing: -0.02em;
    }
    h1 span { color: var(--accent); }

    .card {
      width: 100%;
      max-width: 480px;
      background: var(--card);
      border: 1px solid var(--border);
      border-radius: var(--radius);
      padding: 20px;
      display: flex;
      flex-direction: column;
      gap: 14px;
    }

    label {
      font-size: 0.78rem;
      font-weight: 600;
      color: var(--muted);
      text-transform: uppercase;
      letter-spacing: 0.06em;
      margin-bottom: 4px;
      display: block;
    }

    /* status pill */
    .status-pill {
      display: flex;
      align-items: center;
      gap: 8px;
      font-size: 0.9rem;
      font-weight: 600;
      padding: 10px 14px;
      border-radius: 8px;
      background: var(--bg);
      border: 1px solid var(--border);
    }
    .status-dot {
      width: 10px; height: 10px;
      border-radius: 50%;
      background: var(--muted);
      flex-shrink: 0;
      transition: background 0.2s;
    }
    .status-pill.connecting .status-dot { background: var(--yellow); animation: pulse 1s infinite; }
    .status-pill.connected   .status-dot { background: var(--green); }
    .status-pill.error       .status-dot { background: var(--red); }

    @keyframes pulse {
      0%, 100% { opacity: 1; }
      50%       { opacity: 0.3; }
    }

    /* big connect button */
    #btn-connect {
      width: 100%;
      padding: 16px;
      border: none;
      border-radius: 10px;
      font-size: 1.05rem;
      font-weight: 700;
      font-family: var(--font);
      cursor: pointer;
      transition: background 0.15s, transform 0.1s;
      background: var(--accent);
      color: #fff;
    }
    #btn-connect:active { transform: scale(0.97); }
    #btn-connect.disconnect { background: var(--accent-dim); }
    #btn-connect:disabled { opacity: 0.45; cursor: not-allowed; transform: none; }

    /* stats grid */
    .stats-grid {
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 10px;
    }
    .stat-box {
      background: var(--bg);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 12px 14px;
    }
    .stat-label { font-size: 0.72rem; color: var(--muted); font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em; }
    .stat-value { font-size: 1.35rem; font-weight: 700; margin-top: 2px; }

    /* VU meter */
    .vu-wrap {
      background: var(--bg);
      border: 1px solid var(--border);
      border-radius: 8px;
      padding: 12px 14px;
    }
    .vu-label { font-size: 0.72rem; color: var(--muted); font-weight: 600; text-transform: uppercase; letter-spacing: 0.05em; margin-bottom: 6px; }
    .vu-bar-bg {
      height: 12px;
      background: var(--border);
      border-radius: 6px;
      overflow: hidden;
    }
    .vu-bar-fill {
      height: 100%;
      width: 0%;
      background: linear-gradient(90deg, var(--green), var(--accent), var(--red));
      border-radius: 6px;
      transition: width 0.06s linear;
    }

    .note {
      font-size: 0.78rem;
      color: var(--muted);
      text-align: center;
      line-height: 1.5;
    }
    .note a { color: var(--accent); text-decoration: none; }
  </style>
</head>
<body>
  <h1>Sneeze <span>Detector</span></h1>

  <div class="card">
    <div class="status-pill" id="status-pill">
      <div class="status-dot"></div>
      <span id="status-text">Disconnected</span>
    </div>

    <button id="btn-connect">Connect &amp; Stream</button>
  </div>

  <div class="card">
    <div class="stats-grid">
      <div class="stat-box">
        <div class="stat-label">Packets sent</div>
        <div class="stat-value" id="stat-packets">0</div>
      </div>
      <div class="stat-box">
        <div class="stat-label">Kbps</div>
        <div class="stat-value" id="stat-kbps">—</div>
      </div>
    </div>
    <div class="vu-wrap">
      <div class="vu-label">Mic level</div>
      <div class="vu-bar-bg"><div class="vu-bar-fill" id="vu-fill"></div></div>
    </div>
  </div>

  <p class="note">
    Android Chrome: use HTTP — no extra setup needed.<br/>
    iOS / macOS Safari: start server with <code style="color:var(--accent)">--ssl</code> flag,
    then accept the certificate warning on first visit.
  </p>

  <script>
    // ─── Config ───────────────────────────────────────────────────────────
    const CAPTURE_SR   = 48000;   // must match recv-side capture_sr
    const FRAME_SEC    = 0.10;    // 100 ms frames (must match cfg.FRAME_SEC)
    const FRAME_SAMPLES = CAPTURE_SR * FRAME_SEC;   // 4800 samples

    // ScriptProcessorNode buffer must be power-of-two; we use the closest
    // that is >= FRAME_SAMPLES and chunk them manually.
    const PROC_BUFSIZE = 8192;    // ~170 ms @ 48 kHz

    // ─── DOM ──────────────────────────────────────────────────────────────
    const btnConnect = document.getElementById("btn-connect");
    const pillEl     = document.getElementById("status-pill");
    const statusText = document.getElementById("status-text");
    const statPkts   = document.getElementById("stat-packets");
    const statKbps   = document.getElementById("stat-kbps");
    const vuFill     = document.getElementById("vu-fill");

    // ─── State ────────────────────────────────────────────────────────────
    let ws          = null;
    let audioCtx    = null;
    let micStream   = null;
    let scriptNode  = null;
    let srcNode     = null;
    let pktCount    = 0;
    let bytesSent   = 0;
    let kbpsTimer   = null;
    let prevBytes   = 0;
    let accumBuf    = new Float32Array(0);
    let _sending    = false;   // true once WebSocket is open and audio should be sent

    // ─── UI helpers ───────────────────────────────────────────────────────
    function setStatus(cls, msg) {
      pillEl.className = "status-pill " + cls;
      statusText.textContent = msg;
    }

    function setConnected(on) {
      btnConnect.textContent = on ? "Disconnect" : "Connect & Stream";
      btnConnect.classList.toggle("disconnect", on);
    }

    // ─── Stats ────────────────────────────────────────────────────────────
    function startKbpsTimer() {
      prevBytes = bytesSent;
      kbpsTimer = setInterval(() => {
        const kb = (bytesSent - prevBytes) * 8 / 1000;
        statKbps.textContent = kb.toFixed(1);
        prevBytes = bytesSent;
      }, 1000);
    }

    function stopKbpsTimer() {
      clearInterval(kbpsTimer);
      kbpsTimer = null;
      statKbps.textContent = "—";
    }

    // ─── Connect / Disconnect ─────────────────────────────────────────────
    // Must be async so we can await getUserMedia inside the user-gesture context.
    btnConnect.addEventListener("click", async () => {
      if (ws) {
        disconnect();
      } else {
        await connect();
      }
    });

    async function connect() {
      // Derive WebSocket host/port from the page's own URL.
      // HTTP server runs on ws_port+1, so WebSocket port = http_port - 1.
      const host = window.location.hostname;
      const port = parseInt(window.location.port, 10) || 8080;

      btnConnect.disabled = true;

      // ── Step 1: acquire mic permission NOW, inside the user-gesture context ──
      // AudioContext + getUserMedia must be called synchronously (or awaited)
      // before any async network hop, or Chrome will suspend the AudioContext.
      setStatus("connecting", "Requesting mic…");
      const ok = await startAudio();
      if (!ok) {
        btnConnect.disabled = false;
        return;
      }

      // ── Step 2: connect WebSocket ──
      setStatus("connecting", "Connecting…");
      const wsProto = location.protocol === "https:" ? "wss:" : "ws:";
      const url = `${wsProto}//${host}:${port}/audio`;
      ws = new WebSocket(url);
      ws.binaryType = "arraybuffer";

      ws.onopen = () => {
        setStatus("connected", "Connected");
        setConnected(true);
        btnConnect.disabled = false;
        pktCount = 0; bytesSent = 0;
        statPkts.textContent = "0";
        startKbpsTimer();
        _sending = true;   // audio pipeline already running; start forwarding packets
      };

      ws.onclose = (ev) => {
        _sending = false;
        stopAudio();
        stopKbpsTimer();
        setConnected(false);
        btnConnect.disabled = false;
        ws = null;
        if (ev.code !== 1000) {
          setStatus("error", `Closed (${ev.code})`);
        } else {
          setStatus("", "Disconnected");
        }
      };

      ws.onerror = () => {
        _sending = false;
        stopAudio();
        setStatus("error", "WS connection failed");
        btnConnect.disabled = false;
        ws = null;
      };
    }

    function disconnect() {
      _sending = false;
      stopAudio();
      if (ws) {
        ws.close(1000, "user disconnect");
        ws = null;
      }
      stopKbpsTimer();
      setStatus("", "Disconnected");
      setConnected(false);
    }

    // ─── Audio capture ────────────────────────────────────────────────────
    // Returns true on success, false on error.
    // Call this INSIDE a user-gesture handler (click) to satisfy autoplay policy.
    async function startAudio() {
      try {
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
          throw new Error(
            location.protocol === "https:"
              ? "getUserMedia not supported in this browser."
              : "Mic requires HTTPS. Open this page over https:// or use Chrome on Android."
          );
        }

        audioCtx = new (window.AudioContext || window.webkitAudioContext)({
          sampleRate: CAPTURE_SR,
          latencyHint: "interactive",
        });
        // Explicitly resume — Chrome may start AudioContext in suspended state.
        await audioCtx.resume();

        micStream = await navigator.mediaDevices.getUserMedia({
          audio: {
            channelCount: 1,
            echoCancellation: false,
            noiseSuppression: false,
            autoGainControl: false,
          },
          video: false,
        });

        srcNode    = audioCtx.createMediaStreamSource(micStream);
        scriptNode = audioCtx.createScriptProcessor(PROC_BUFSIZE, 1, 1);
        accumBuf   = new Float32Array(0);

        scriptNode.onaudioprocess = (ev) => {
          const input = ev.inputBuffer.getChannelData(0);

          // VU meter (always active once mic is running)
          let sum = 0;
          for (let i = 0; i < input.length; i++) sum += input[i] * input[i];
          const pct = Math.min(100, Math.sqrt(sum / input.length) * 400);
          vuFill.style.width = pct.toFixed(1) + "%";

          if (!_sending) return;   // WebSocket not open yet — VU meter still works

          // Accumulate and drain in FRAME_SAMPLES chunks
          const merged = new Float32Array(accumBuf.length + input.length);
          merged.set(accumBuf);
          merged.set(input, accumBuf.length);
          accumBuf = merged;

          while (accumBuf.length >= FRAME_SAMPLES) {
            const frame = accumBuf.slice(0, FRAME_SAMPLES);
            accumBuf    = accumBuf.slice(FRAME_SAMPLES);

            if (ws && ws.readyState === WebSocket.OPEN) {
              ws.send(frame.buffer);   // raw float32 LE — same as UDP send.py
              pktCount++;
              bytesSent += frame.buffer.byteLength;
              statPkts.textContent = pktCount.toString();
            }
          }
        };

        srcNode.connect(scriptNode);
        scriptNode.connect(audioCtx.destination);
        return true;

      } catch (err) {
        setStatus("error", "Mic: " + err.message);
        if (audioCtx) { audioCtx.close(); audioCtx = null; }
        micStream = null;
        return false;
      }
    }

    function stopAudio() {
      if (scriptNode) { scriptNode.disconnect(); scriptNode = null; }
      if (srcNode)    { srcNode.disconnect();    srcNode    = null; }
      if (micStream)  { micStream.getTracks().forEach(t => t.stop()); micStream = null; }
      if (audioCtx)   { audioCtx.close();        audioCtx   = null; }
      vuFill.style.width = "0%";
      accumBuf = new Float32Array(0);
    }
  </script>
</body>
</html>
