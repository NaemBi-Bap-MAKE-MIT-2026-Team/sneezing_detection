# Codebase Documentation — Legacy V4

## Overview

V4 is the latest iteration of the sneezing detection system. It replaces the Keras/TensorFlow model used in V1–V3 with a **TensorFlow Lite (TFLite)** model optimised for deployment on resource-constrained hardware, specifically the **Raspberry Pi 4 (2 GB RAM)**. V4 ships two runtime modes: one that saves detected audio to disk and one that runs inference-only with no file I/O.

---

## Directory Structure

```
legacy_code/output/v4/
├── test_saving_v4.py       # Real-time detection; saves audio clips of detected sneezes
└── test_no_saving_v4.py    # Real-time detection; inference-only, no file I/O
```

Supporting assets (not stored in this directory but required at runtime):

| File | Description |
|---|---|
| `v4_model.tflite` | Quantised TFLite model (generated by training notebooks) |
| `v4_norm_stats.npz` | Z-score normalisation statistics (µ and σ per mel band) |

Training notebooks are kept under `legacy_code/notebooks/`:
- `train_colab_v4.ipynb` — trains V4 on Google Colab
- `train_local_v4.ipynb` — trains V4 locally

---

## Files

### `test_saving_v4.py`

**Purpose:** Real-time sneeze detection with automatic saving of positive audio clips.

**Key behaviour:**
1. Opens the default microphone at 48 kHz (avoids Windows driver issues at lower rates).
2. Maintains a rolling pre-buffer (500 ms) so the onset of a sneeze is not lost.
3. When the RMS of the incoming frame exceeds `RMS_TRIGGER_TH`, a 2-second clip is assembled.
4. The clip is resampled to 16 kHz and passed through the preprocessing pipeline.
5. The TFLite model returns a sneeze probability.
6. If `prob >= PROB_TH` and the cooldown period has elapsed, the detection is logged, "bless you!" is printed, and the clip is saved as `sneeze_{timestamp}_{idx:04d}_p{prob:.3f}.wav`.

**Configuration constants:**

| Constant | Value | Description |
|---|---|---|
| `TFLITE_PATH` | `v4_model.tflite` | Path to the TFLite model |
| `STATS_PATH` | `v4_norm_stats.npz` | Path to normalisation statistics |
| `CAPTURE_SR` | 48 000 Hz | Microphone sample rate |
| `MODEL_SR` | 16 000 Hz | Model input sample rate |
| `CLIP_SECONDS` | 2.0 s | Duration of each analysis window |
| `RMS_TRIGGER_TH` | 0.008 | RMS amplitude threshold to start capture |
| `PROB_TH` | 0.90 | Minimum probability to declare a sneeze |
| `N_MELS` | 64 | Number of mel filter banks |
| `N_FFT` | 400 | FFT window size |
| `HOP` | 160 | Hop length |
| `CENTER` | `False` | Disable librosa centering (must match training) |
| `TARGET_RMS` | 0.1 | Target RMS for normalisation |
| `COOLDOWN_S` | 1.5 s | Minimum gap between two detections |

**Preprocessing pipeline (`preproc()`):**

```
raw 48 kHz clip
    └─ resample → 16 kHz
    └─ pad / trim to exactly 32 000 samples (2 s)
    └─ RMS normalise (target = 0.1, clip to [-1, 1])
    └─ log-mel spectrogram → shape (frames, 64)
    └─ z-score normalise per mel band using loaded µ / σ
    └─ reshape to (1, frames, 64, 1)   ← TFLite input tensor
```

**Model I/O:**

| Tensor | Shape | dtype |
|---|---|---|
| Input | `(1, frames, 64, 1)` | `float32` |
| Output | `(1, 1)` | `float32` (sneeze probability) |

**Output file naming:**
```
sneeze_YYYYMMDD_HHMMSS_0001_p0.953.wav
```

---

### `test_no_saving_v4.py`

**Purpose:** Identical to `test_saving_v4.py` but omits all file I/O after detection.

**Differences from `test_saving_v4.py`:**
- No WAV file is written on detection.
- No save-directory creation or indexing logic.
- Slightly lower CPU and I/O overhead — preferred when storage is limited or the deployment environment is write-restricted.
- All audio processing, model inference, thresholding, cooldown, and console output remain identical.

---

## Simulation Framework

A companion simulation framework lives at `legacy_code/simulation/` and enables desktop testing of the V4 pipeline **without** physical hardware or a real TFLite model.

| Module | Purpose |
|---|---|
| `mock_tflite_interpreter.py` | Drop-in `MockInterpreter` that mimics the TFLite runtime API |
| `rpi4_resource_simulator.py` | `CPUThrottler`, `MemoryMonitor`, `TimingProfiler` to emulate RPi4 resources |
| `v4_pipeline.py` | Self-contained copy of all V4 preprocessing functions |
| `run_simulation.py` | CLI runner — processes WAV files and prints a timing / pass-fail report |

### RPi4 CPU Throttling Factors

| Stage | Slowdown |
|---|---|
| Resample (48 k → 16 k) | 7× |
| Log-mel spectrogram | 5× |
| RMS + z-score normalise | 3× |
| TFLite invoke | 4× |
| WAV file I/O | 2× |
| Pad / trim | 2× |

### Running the Simulation

```bash
python -m legacy_code.simulation.run_simulation \
    --wav-dir /path/to/wav/files \
    --fake-output 0.95 \
    --inference-delay-ms 10 \
    --budget-ms 1000
```

---

## Performance Characteristics

| Metric | Estimate |
|---|---|
| End-to-end latency | ~2.1 s (2 s capture window + ~100–180 ms processing) |
| Desktop processing time | 80–120 ms per 2 s window |
| RPi4 estimated processing time | 120–180 ms per 2 s window |
| RPi4 CPU usage | 30–45 % |
| RPi4 memory footprint | ~80 MB |
| TFLite inference time (RPi4) | 10–50 ms |

---

## Dependencies

| Library | Usage |
|---|---|
| `sounddevice` | Real-time microphone capture |
| `numpy` | Array operations |
| `librosa` | Resampling and mel spectrogram computation |
| `scipy` | WAV file writing (`scipy.io.wavfile`) |
| `tflite_runtime` | TFLite inference (RPi4) or `tensorflow.lite` (desktop) |

Install on Raspberry Pi:
```bash
pip install sounddevice numpy librosa scipy
pip install tflite-runtime  # lightweight, no full TF required
```

---

## Relation to Other Versions

| Version | Model Format | Feature | Platform |
|---|---|---|---|
| V1 | Keras `.keras` | MFCC (20 coeff + deltas) | Desktop |
| V2 | Keras `.keras` | MFCC filtered | Desktop |
| V3 / V3.1 / V3.2 | Keras `.keras` | Log-mel spectrogram | Desktop |
| **V4** | **TFLite `.tflite`** | **64-band log-mel spectrogram** | **Raspberry Pi 4** |

---

## Known Constraints

- `CENTER=False` in the mel spectrogram must match the value used during training. Changing it will produce mismatched feature vectors and degrade accuracy.
- The model and normalisation statistics (`v4_model.tflite`, `v4_norm_stats.npz`) are not included in the repository and must be generated by running one of the V4 training notebooks.
- Audio capture uses 48 kHz to maintain compatibility with common Windows audio drivers; the signal is downsampled to 16 kHz before feature extraction.
- A 1.5-second cooldown prevents duplicate detections from a single sneeze event.
