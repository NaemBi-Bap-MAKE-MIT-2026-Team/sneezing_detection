{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce63d999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: c:\\Dev\\sneezing_detection\\legacy_code\n",
      "DATA: c:\\Dev\\sneezing_detection\\legacy_code\\data\n",
      "OUT : c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, random, time, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# 스레드 폭주 방지(로컬에서도 안정성에 도움)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# 프로젝트 루트: 이 파일(노트북)이 notebooks/ 아래에 있다고 가정\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "DATA = ROOT / \"data\"\n",
    "OUT  = ROOT / \"out\" / \"v4\"\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ESC50_DIR   = DATA / \"esc-50\"\n",
    "MS_SNSD_DIR = DATA / \"MS-SNSD-NOISE\"\n",
    "SNEEZE_DIR  = DATA / \"sneeze\"\n",
    "REC_DIR     = DATA / \"recordings\"\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA:\", DATA)\n",
    "print(\"OUT :\", OUT)\n",
    "\n",
    "assert ESC50_DIR.exists(), ESC50_DIR\n",
    "assert MS_SNSD_DIR.exists(), MS_SNSD_DIR\n",
    "assert SNEEZE_DIR.exists(), SNEEZE_DIR\n",
    "assert REC_DIR.exists(), REC_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7efaf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\config_v4.json\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = OUT / \"config_v4.json\"\n",
    "\n",
    "cfg = {\n",
    "  \"version\": \"v4\",\n",
    "  \"seed\": 1337,\n",
    "  \"audio\": {\"sr\": 16000, \"clip_seconds\": 2.0},\n",
    "  \"features\": {\"type\":\"logmel\",\"n_mels\":64,\"n_fft\":400,\"hop_length\":160,\"center\":False,\"log_eps\":1e-6},\n",
    "  \"normalization\": {\"mode\":\"dataset_stats\",\"rms_target_range\":[0.03,0.15],\"rms_apply_prob\":1.0},\n",
    "  \"dataset_sizes\": {\"pos_total\":12000,\"neg_total\":30000,\"pos_mix_ratio\":0.70},\n",
    "  \"negative_plan\": {\n",
    "    \"event_ratio\":0.60,\"background_ratio\":0.40,\n",
    "    \"event_sources\":{\"esc50_excluding_sneeze\":0.40,\"yaho\":0.35,\"noise1_noise2\":0.25},\n",
    "    \"background_sources\":{\"ms_snsd\":0.50,\"talk\":0.30,\"dish\":0.20}\n",
    "  },\n",
    "  \"positive_plan\": {\n",
    "    \"original_ratio\":0.30,\"synthetic_ratio\":0.70,\n",
    "    \"background_pool\":{\"ms_snsd\":0.40,\"talk\":0.40,\"dish\":0.20},\n",
    "    \"snr_db_range_bg\":[0.0,20.0],\n",
    "    \"optional_event_on_pos\":{\n",
    "      \"apply_prob\":0.15,\n",
    "      \"event_pool\":{\"yaho\":0.50,\"esc50_excluding_sneeze\":0.30,\"noise1_noise2\":0.20},\n",
    "      \"snr_db_range_event\":[15.0,30.0]\n",
    "    }\n",
    "  },\n",
    "  \"augment\": {\n",
    "    \"gain_db_range\":[-6.0,6.0],\n",
    "    \"time_shift_ms\":200,\n",
    "    \"time_stretch\":{\"apply_prob\":0.10,\"rate_range\":[0.95,1.05]},\n",
    "    \"pitch_shift\":{\"apply_prob\":0.05,\"semitones_range\":[-0.25,0.25]},\n",
    "    \"specaugment\":{\"apply_prob\":0.10,\"time_masks\":1,\"time_mask_max\":12,\"freq_masks\":1,\"freq_mask_max\":6}\n",
    "  },\n",
    "  \"splits\": {\"train\":0.70,\"val\":0.15,\"test\":0.15},\n",
    "  \"training\": {\"batch_size\":64,\"epochs\":100,\"lr\":0.001,\"early_stopping_patience\":6,\"reduce_lr_patience\":2,\"reduce_lr_factor\":0.5},\n",
    "  \"thresholding\": {\"method\":\"precision_target\",\"target_precision\":0.99,\"fallback_threshold\":0.90},\n",
    "  \"export\": {\"tflite_dynamic\":True}\n",
    "}\n",
    "\n",
    "CONFIG_PATH.write_text(json.dumps(cfg, indent=2), encoding=\"utf-8\")\n",
    "print(\"saved:\", CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2827412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a085e04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1337\n"
     ]
    }
   ],
   "source": [
    "SEED = int(cfg[\"seed\"])\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(\"seed:\", SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83a7e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sneeze clips: 968\n",
      "esc-50 event files(excl sneeze): 2000\n",
      "ms-snsd wav files: 128\n"
     ]
    }
   ],
   "source": [
    "# recordings 필수 파일\n",
    "TALK_WAV   = REC_DIR / \"talk.wav\"\n",
    "DISH_WAV   = REC_DIR / \"dish.wav\"\n",
    "YAHO_WAV   = REC_DIR / \"yaho.wav\"\n",
    "NOISE1_WAV = REC_DIR / \"noise1.wav\"\n",
    "NOISE2_WAV = REC_DIR / \"noise2.wav\"\n",
    "\n",
    "for p in [TALK_WAV, DISH_WAV, YAHO_WAV, NOISE1_WAV, NOISE2_WAV]:\n",
    "    assert p.exists(), f\"missing: {p}\"\n",
    "\n",
    "# sneeze clips\n",
    "sneeze_files = sorted([p for p in SNEEZE_DIR.rglob(\"*.wav\")])\n",
    "assert len(sneeze_files) > 0\n",
    "print(\"sneeze clips:\", len(sneeze_files))\n",
    "\n",
    "# ESC-50\n",
    "esc_meta = ESC50_DIR / \"meta\" / \"esc50.csv\"\n",
    "esc_audio_dir = ESC50_DIR / \"audio\"\n",
    "assert esc_meta.exists(), esc_meta\n",
    "assert esc_audio_dir.exists(), esc_audio_dir\n",
    "\n",
    "esc_rows = []\n",
    "with open(esc_meta, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = csv.DictReader(f)\n",
    "    for row in r:\n",
    "        esc_rows.append(row)\n",
    "\n",
    "esc_event_files = []\n",
    "for row in esc_rows:\n",
    "    label = row[\"category\"].strip().lower()\n",
    "    fname = row[\"filename\"].strip()\n",
    "    if \"sneeze\" in label:\n",
    "        continue\n",
    "    wav = esc_audio_dir / fname\n",
    "    if wav.exists():\n",
    "        esc_event_files.append(wav)\n",
    "\n",
    "print(\"esc-50 event files(excl sneeze):\", len(esc_event_files))\n",
    "\n",
    "# MS-SNSD\n",
    "ms_snsd_files = sorted([p for p in MS_SNSD_DIR.rglob(\"*.wav\")])\n",
    "assert len(ms_snsd_files) > 0\n",
    "print(\"ms-snsd wav files:\", len(ms_snsd_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "417f86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = int(cfg[\"audio\"][\"sr\"])\n",
    "CLIP_SEC = float(cfg[\"audio\"][\"clip_seconds\"])\n",
    "CLIP_SAMPLES = int(SR * CLIP_SEC)\n",
    "\n",
    "N_MELS = int(cfg[\"features\"][\"n_mels\"])\n",
    "N_FFT  = int(cfg[\"features\"][\"n_fft\"])\n",
    "HOP    = int(cfg[\"features\"][\"hop_length\"])\n",
    "CENTER = bool(cfg[\"features\"][\"center\"])\n",
    "LOG_EPS = float(cfg[\"features\"][\"log_eps\"])\n",
    "\n",
    "def rms(x):\n",
    "    x = np.asarray(x, np.float32)\n",
    "    return float(np.sqrt(np.mean(x*x) + 1e-8))\n",
    "\n",
    "def fix_2s(y):\n",
    "    y = np.asarray(y, np.float32)\n",
    "    if len(y) >= CLIP_SAMPLES:\n",
    "        return y[:CLIP_SAMPLES]\n",
    "    return np.pad(y, (0, CLIP_SAMPLES - len(y))).astype(np.float32)\n",
    "\n",
    "def rand_crop_2s(y):\n",
    "    y = np.asarray(y, np.float32)\n",
    "    if len(y) <= CLIP_SAMPLES:\n",
    "        return fix_2s(y)\n",
    "    start = np.random.randint(0, len(y) - CLIP_SAMPLES + 1)\n",
    "    return y[start:start+CLIP_SAMPLES].astype(np.float32)\n",
    "\n",
    "def load_mono(path, sr=SR):\n",
    "    y, _ = librosa.load(str(path), sr=sr, mono=True)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def apply_gain_db(y, db):\n",
    "    g = 10 ** (db / 20.0)\n",
    "    return np.clip(y * g, -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def rms_randomize(y, lo, hi):\n",
    "    target = float(np.random.uniform(lo, hi))\n",
    "    r = rms(y)\n",
    "    if r > 1e-6:\n",
    "        y = y * (target / (r + 1e-8))\n",
    "    return np.clip(y, -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def mix_at_snr(signal, background, snr_db):\n",
    "    s = fix_2s(signal)\n",
    "    b = fix_2s(background)\n",
    "    rs, rb = rms(s), rms(b)\n",
    "    if rb < 1e-6:\n",
    "        return s\n",
    "    alpha = (rs + 1e-8) / ((rb + 1e-8) * (10 ** (snr_db / 20.0)))\n",
    "    y = s + b * alpha\n",
    "    return np.clip(y, -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def time_shift(y, max_ms=200):\n",
    "    max_samp = int(SR * (max_ms / 1000.0))\n",
    "    if max_samp <= 0:\n",
    "        return y\n",
    "    k = np.random.randint(-max_samp, max_samp + 1)\n",
    "    return np.roll(y, k).astype(np.float32)\n",
    "\n",
    "def maybe_time_stretch(y, prob, r_lo, r_hi):\n",
    "    if np.random.rand() > prob:\n",
    "        return y\n",
    "    rate = float(np.random.uniform(r_lo, r_hi))\n",
    "    ys = librosa.effects.time_stretch(y, rate=rate).astype(np.float32)\n",
    "    return fix_2s(ys)\n",
    "\n",
    "def maybe_pitch_shift(y, prob, s_lo, s_hi):\n",
    "    if np.random.rand() > prob:\n",
    "        return y\n",
    "    steps = float(np.random.uniform(s_lo, s_hi))\n",
    "    yp = librosa.effects.pitch_shift(y, sr=SR, n_steps=steps).astype(np.float32)\n",
    "    return fix_2s(yp)\n",
    "\n",
    "def logmel(y):\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=N_FFT, hop_length=HOP,\n",
    "        n_mels=N_MELS, power=2.0, center=CENTER\n",
    "    )\n",
    "    return np.log(S + LOG_EPS).T.astype(np.float32)  # (frames, mels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1a459f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hmchung\\anaconda3\\envs\\sneeze-detection\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "talk_audio  = load_mono(TALK_WAV)\n",
    "dish_audio  = load_mono(DISH_WAV)\n",
    "yaho_audio  = load_mono(YAHO_WAV)\n",
    "noise1_audio = load_mono(NOISE1_WAV)\n",
    "noise2_audio = load_mono(NOISE2_WAV)\n",
    "\n",
    "def sample_from_long(y_long):\n",
    "    return rand_crop_2s(y_long)\n",
    "\n",
    "def sample_esc50_2s(path):\n",
    "    y = load_mono(path)\n",
    "    return rand_crop_2s(y)\n",
    "\n",
    "def sample_ms_snsd_2s(path):\n",
    "    y = load_mono(path)\n",
    "    return rand_crop_2s(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f40aa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRAMES: 198 MELS: 64 N_TOTAL: 42000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos_original: 100%|██████████| 3600/3600 [00:39<00:00, 91.66it/s] \n",
      "pos_synth: 100%|██████████| 8400/8400 [01:47<00:00, 78.40it/s] \n",
      "neg_bg: 100%|██████████| 12000/12000 [02:23<00:00, 83.51it/s] \n",
      "neg_event: 100%|██████████| 18000/18000 [03:43<00:00, 80.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written: 42000 expected: 42000\n",
      "saved: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\v4_meta.json\n"
     ]
    }
   ],
   "source": [
    "pos_total = int(cfg[\"dataset_sizes\"][\"pos_total\"])\n",
    "neg_total = int(cfg[\"dataset_sizes\"][\"neg_total\"])\n",
    "N_TOTAL = pos_total + neg_total\n",
    "\n",
    "tmp = logmel(np.zeros(CLIP_SAMPLES, np.float32))\n",
    "FRAMES = int(tmp.shape[0])\n",
    "assert tmp.shape[1] == N_MELS\n",
    "print(\"FRAMES:\", FRAMES, \"MELS:\", N_MELS, \"N_TOTAL:\", N_TOTAL)\n",
    "\n",
    "X_PATH = OUT / \"v4_features_f32.dat\"\n",
    "Y_PATH = OUT / \"v4_labels_i8.dat\"\n",
    "META_PATH = OUT / \"v4_meta.json\"\n",
    "\n",
    "# 이미 존재하면 재생성 여부 결정(실수 방지)\n",
    "if X_PATH.exists() or Y_PATH.exists():\n",
    "    print(\"memmap exists. delete to regenerate:\", X_PATH, Y_PATH)\n",
    "\n",
    "X_mm = np.memmap(str(X_PATH), dtype=\"float32\", mode=\"w+\", shape=(N_TOTAL, FRAMES, N_MELS))\n",
    "y_mm = np.memmap(str(Y_PATH), dtype=\"int8\", mode=\"w+\", shape=(N_TOTAL,))\n",
    "\n",
    "sum_m = np.zeros((N_MELS,), np.float64)\n",
    "sumsq_m = np.zeros((N_MELS,), np.float64)\n",
    "count_tf = 0\n",
    "\n",
    "def weighted_choice(items, weights):\n",
    "    w = np.asarray(weights, np.float64)\n",
    "    w = w / w.sum()\n",
    "    idx = np.random.choice(len(items), p=w)\n",
    "    return items[idx]\n",
    "\n",
    "pos_original_n = int(pos_total * float(cfg[\"positive_plan\"][\"original_ratio\"]))\n",
    "pos_synth_n    = pos_total - pos_original_n\n",
    "neg_event_n = int(neg_total * float(cfg[\"negative_plan\"][\"event_ratio\"]))\n",
    "neg_bg_n    = neg_total - neg_event_n\n",
    "\n",
    "bg_pool_items = [\"ms_snsd\", \"talk\", \"dish\"]\n",
    "bg_pool_w = [\n",
    "    cfg[\"positive_plan\"][\"background_pool\"][\"ms_snsd\"],\n",
    "    cfg[\"positive_plan\"][\"background_pool\"][\"talk\"],\n",
    "    cfg[\"positive_plan\"][\"background_pool\"][\"dish\"],\n",
    "]\n",
    "\n",
    "pos_evt_items = [\"yaho\", \"esc\", \"noise12\"]\n",
    "pos_evt_w = [\n",
    "    cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"event_pool\"][\"yaho\"],\n",
    "    cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"event_pool\"][\"esc50_excluding_sneeze\"],\n",
    "    cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"event_pool\"][\"noise1_noise2\"],\n",
    "]\n",
    "\n",
    "neg_evt_items = [\"esc\", \"yaho\", \"noise12\"]\n",
    "neg_evt_w = [\n",
    "    cfg[\"negative_plan\"][\"event_sources\"][\"esc50_excluding_sneeze\"],\n",
    "    cfg[\"negative_plan\"][\"event_sources\"][\"yaho\"],\n",
    "    cfg[\"negative_plan\"][\"event_sources\"][\"noise1_noise2\"],\n",
    "]\n",
    "\n",
    "neg_bg_items = [\"ms_snsd\", \"talk\", \"dish\"]\n",
    "neg_bg_w = [\n",
    "    cfg[\"negative_plan\"][\"background_sources\"][\"ms_snsd\"],\n",
    "    cfg[\"negative_plan\"][\"background_sources\"][\"talk\"],\n",
    "    cfg[\"negative_plan\"][\"background_sources\"][\"dish\"],\n",
    "]\n",
    "\n",
    "rms_lo, rms_hi = cfg[\"normalization\"][\"rms_target_range\"]\n",
    "snr_bg_lo, snr_bg_hi = cfg[\"positive_plan\"][\"snr_db_range_bg\"]\n",
    "pos_evt_prob = float(cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"apply_prob\"])\n",
    "snr_evt_lo, snr_evt_hi = cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"snr_db_range_event\"]\n",
    "\n",
    "aug = cfg[\"augment\"]\n",
    "gain_lo, gain_hi = aug[\"gain_db_range\"]\n",
    "shift_ms = int(aug[\"time_shift_ms\"])\n",
    "ts_prob = float(aug[\"time_stretch\"][\"apply_prob\"])\n",
    "ts_lo, ts_hi = aug[\"time_stretch\"][\"rate_range\"]\n",
    "ps_prob = float(aug[\"pitch_shift\"][\"apply_prob\"])\n",
    "ps_lo, ps_hi = aug[\"pitch_shift\"][\"semitones_range\"]\n",
    "\n",
    "def sample_background(source_name):\n",
    "    if source_name == \"talk\":\n",
    "        return sample_from_long(talk_audio)\n",
    "    if source_name == \"dish\":\n",
    "        return sample_from_long(dish_audio)\n",
    "    if source_name == \"ms_snsd\":\n",
    "        return sample_ms_snsd_2s(random.choice(ms_snsd_files))\n",
    "    raise ValueError(source_name)\n",
    "\n",
    "def sample_event(source_name):\n",
    "    if source_name == \"yaho\":\n",
    "        return sample_from_long(yaho_audio)\n",
    "    if source_name == \"noise12\":\n",
    "        return sample_from_long(noise1_audio if np.random.rand() < 0.5 else noise2_audio)\n",
    "    if source_name == \"esc\":\n",
    "        return sample_esc50_2s(random.choice(esc_event_files))\n",
    "    raise ValueError(source_name)\n",
    "\n",
    "def apply_audio_aug(y):\n",
    "    y = apply_gain_db(y, float(np.random.uniform(gain_lo, gain_hi)))\n",
    "    y = time_shift(y, max_ms=shift_ms)\n",
    "    y = maybe_time_stretch(y, ts_prob, ts_lo, ts_hi)\n",
    "    y = maybe_pitch_shift(y, ps_prob, ps_lo, ps_hi)\n",
    "    y = rms_randomize(y, rms_lo, rms_hi)\n",
    "    return y\n",
    "\n",
    "def write_feature(i, y_audio, label):\n",
    "    global sum_m, sumsq_m, count_tf\n",
    "    f = logmel(y_audio)\n",
    "    if f.shape[0] > FRAMES:\n",
    "        f = f[:FRAMES, :]\n",
    "    elif f.shape[0] < FRAMES:\n",
    "        f = np.pad(f, ((0, FRAMES - f.shape[0]), (0, 0)), mode=\"constant\")\n",
    "\n",
    "    X_mm[i, :, :] = f.astype(np.float32)\n",
    "    y_mm[i] = np.int8(label)\n",
    "\n",
    "    sum_m += f.sum(axis=0)\n",
    "    sumsq_m += (f * f).sum(axis=0)\n",
    "    count_tf += f.shape[0]\n",
    "\n",
    "i = 0\n",
    "\n",
    "for _ in tqdm(range(pos_original_n), desc=\"pos_original\"):\n",
    "    p = random.choice(sneeze_files)\n",
    "    y = apply_audio_aug(rand_crop_2s(load_mono(p)))\n",
    "    write_feature(i, y, 1); i += 1\n",
    "\n",
    "for _ in tqdm(range(pos_synth_n), desc=\"pos_synth\"):\n",
    "    p = random.choice(sneeze_files)\n",
    "    sneeze = rand_crop_2s(load_mono(p))\n",
    "    bg = sample_background(weighted_choice(bg_pool_items, bg_pool_w))\n",
    "    snr_bg = float(np.random.uniform(snr_bg_lo, snr_bg_hi))\n",
    "    y = mix_at_snr(sneeze, bg, snr_bg)\n",
    "\n",
    "    if np.random.rand() < pos_evt_prob:\n",
    "        evt = sample_event(weighted_choice(pos_evt_items, pos_evt_w))\n",
    "        snr_evt = float(np.random.uniform(snr_evt_lo, snr_evt_hi))\n",
    "        y = mix_at_snr(y, evt, snr_evt)\n",
    "\n",
    "    y = apply_audio_aug(y)\n",
    "    write_feature(i, y, 1); i += 1\n",
    "\n",
    "for _ in tqdm(range(neg_bg_n), desc=\"neg_bg\"):\n",
    "    y = apply_audio_aug(sample_background(weighted_choice(neg_bg_items, neg_bg_w)))\n",
    "    write_feature(i, y, 0); i += 1\n",
    "\n",
    "for _ in tqdm(range(neg_event_n), desc=\"neg_event\"):\n",
    "    y = sample_event(weighted_choice(neg_evt_items, neg_evt_w))\n",
    "    if np.random.rand() < 0.50:\n",
    "        bg = sample_background(weighted_choice(neg_bg_items, neg_bg_w))\n",
    "        snr = float(np.random.uniform(5.0, 25.0))\n",
    "        y = mix_at_snr(y, bg, snr)\n",
    "    y = apply_audio_aug(y)\n",
    "    write_feature(i, y, 0); i += 1\n",
    "\n",
    "X_mm.flush()\n",
    "y_mm.flush()\n",
    "\n",
    "meta = {\n",
    "  \"version\":\"v4\",\n",
    "  \"sr\":SR, \"clip_seconds\":CLIP_SEC,\n",
    "  \"frames\":FRAMES, \"mels\":N_MELS,\n",
    "  \"n_total\":int(N_TOTAL),\n",
    "  \"pos_total\":int(pos_total),\n",
    "  \"neg_total\":int(neg_total),\n",
    "  \"features_path\":str(X_PATH),\n",
    "  \"labels_path\":str(Y_PATH),\n",
    "}\n",
    "META_PATH.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"written:\", i, \"expected:\", N_TOTAL)\n",
    "print(\"saved:\", META_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92c4ee01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\v4_norm_stats.npz mu: (64,) sd: (64,)\n"
     ]
    }
   ],
   "source": [
    "mu = (sum_m / max(1, count_tf)).astype(np.float32)\n",
    "var = (sumsq_m / max(1, count_tf) - (mu.astype(np.float64) ** 2))\n",
    "var = np.maximum(var, 1e-8).astype(np.float32)\n",
    "sd  = np.sqrt(var).astype(np.float32)\n",
    "\n",
    "STATS_PATH = OUT / \"v4_norm_stats.npz\"\n",
    "np.savez(STATS_PATH, mu=mu, sd=sd)\n",
    "print(\"saved:\", STATS_PATH, \"mu:\", mu.shape, \"sd:\", sd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d44911bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train n= 29399 pos= 8400 neg= 20999\n",
      "val   n= 6300 pos= 1800 neg= 4500\n",
      "test  n= 6301 pos= 1800 neg= 4501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_all = np.array(np.memmap(str(Y_PATH), dtype=\"int8\", mode=\"r\", shape=(N_TOTAL,)), dtype=np.int64)\n",
    "idx = np.arange(len(y_all))\n",
    "\n",
    "idx_train, idx_tmp, y_train, y_tmp = train_test_split(\n",
    "    idx, y_all, test_size=(1.0 - cfg[\"splits\"][\"train\"]), random_state=SEED, stratify=y_all\n",
    ")\n",
    "val_ratio = cfg[\"splits\"][\"val\"] / (cfg[\"splits\"][\"val\"] + cfg[\"splits\"][\"test\"])\n",
    "idx_val, idx_test, y_val, y_test = train_test_split(\n",
    "    idx_tmp, y_tmp, test_size=(1.0 - val_ratio), random_state=SEED, stratify=y_tmp\n",
    ")\n",
    "\n",
    "def counts(name, idxs):\n",
    "    yy = y_all[idxs]\n",
    "    print(name, \"n=\", len(idxs), \"pos=\", int(yy.sum()), \"neg=\", int((yy==0).sum()))\n",
    "\n",
    "counts(\"train\", idx_train)\n",
    "counts(\"val  \", idx_val)\n",
    "counts(\"test \", idx_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873d38eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 64ms/step - auc: 0.8048 - loss: 0.4655 - prec: 0.7342 - rec: 0.4152 - val_auc: 0.8999 - val_loss: 0.3648 - val_prec: 0.7774 - val_rec: 0.5683 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - auc: 0.9074 - loss: 0.3413 - prec: 0.7751 - rec: 0.6957 - val_auc: 0.9230 - val_loss: 0.3209 - val_prec: 0.7936 - val_rec: 0.6878 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 65ms/step - auc: 0.9269 - loss: 0.3063 - prec: 0.8021 - rec: 0.7396 - val_auc: 0.9326 - val_loss: 0.3099 - val_prec: 0.7256 - val_rec: 0.8183 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 64ms/step - auc: 0.9363 - loss: 0.2867 - prec: 0.8167 - rec: 0.7660 - val_auc: 0.9458 - val_loss: 0.2899 - val_prec: 0.8953 - val_rec: 0.6564 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 63ms/step - auc: 0.9437 - loss: 0.2698 - prec: 0.8324 - rec: 0.7829 - val_auc: 0.9509 - val_loss: 0.2559 - val_prec: 0.8266 - val_rec: 0.7987 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - auc: 0.9513 - loss: 0.2516 - prec: 0.8470 - rec: 0.7957 - val_auc: 0.9544 - val_loss: 0.2509 - val_prec: 0.7938 - val_rec: 0.8410 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - auc: 0.9560 - loss: 0.2392 - prec: 0.8519 - rec: 0.8105 - val_auc: 0.9509 - val_loss: 0.2496 - val_prec: 0.8538 - val_rec: 0.8004 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9583 - loss: 0.2330 - prec: 0.8531 - rec: 0.8183 - val_auc: 0.9622 - val_loss: 0.2329 - val_prec: 0.9034 - val_rec: 0.7562 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 60ms/step - auc: 0.9613 - loss: 0.2244 - prec: 0.8614 - rec: 0.8285 - val_auc: 0.9623 - val_loss: 0.2214 - val_prec: 0.8708 - val_rec: 0.8157 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9659 - loss: 0.2110 - prec: 0.8683 - rec: 0.8410 - val_auc: 0.9682 - val_loss: 0.2064 - val_prec: 0.8831 - val_rec: 0.8157 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9668 - loss: 0.2072 - prec: 0.8743 - rec: 0.8476 - val_auc: 0.9692 - val_loss: 0.2017 - val_prec: 0.8617 - val_rec: 0.8531 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9676 - loss: 0.2042 - prec: 0.8730 - rec: 0.8513 - val_auc: 0.9707 - val_loss: 0.2165 - val_prec: 0.9309 - val_rec: 0.7565 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - auc: 0.9700 - loss: 0.1962 - prec: 0.8802 - rec: 0.8614 - val_auc: 0.9708 - val_loss: 0.1999 - val_prec: 0.9037 - val_rec: 0.8109 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 58ms/step - auc: 0.9721 - loss: 0.1893 - prec: 0.8833 - rec: 0.8620 - val_auc: 0.9733 - val_loss: 0.1918 - val_prec: 0.9151 - val_rec: 0.8115 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 56ms/step - auc: 0.9730 - loss: 0.1851 - prec: 0.8872 - rec: 0.8676 - val_auc: 0.9763 - val_loss: 0.1893 - val_prec: 0.9225 - val_rec: 0.7920 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 57ms/step - auc: 0.9734 - loss: 0.1838 - prec: 0.8867 - rec: 0.8733 - val_auc: 0.9733 - val_loss: 0.1998 - val_prec: 0.9298 - val_rec: 0.7942 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9755 - loss: 0.1764 - prec: 0.8893 - rec: 0.8713 - val_auc: 0.9775 - val_loss: 0.1717 - val_prec: 0.9081 - val_rec: 0.8591 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9764 - loss: 0.1728 - prec: 0.8917 - rec: 0.8736 - val_auc: 0.9769 - val_loss: 0.1963 - val_prec: 0.8180 - val_rec: 0.9341 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - auc: 0.9780 - loss: 0.1680 - prec: 0.8930 - rec: 0.8805 - val_auc: 0.9785 - val_loss: 0.1716 - val_prec: 0.9205 - val_rec: 0.8331 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9788 - loss: 0.1634 - prec: 0.8969 - rec: 0.8874 - val_auc: 0.9790 - val_loss: 0.1644 - val_prec: 0.9187 - val_rec: 0.8644 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 59ms/step - auc: 0.9797 - loss: 0.1600 - prec: 0.9016 - rec: 0.8869 - val_auc: 0.9814 - val_loss: 0.1546 - val_prec: 0.9115 - val_rec: 0.8789 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 61ms/step - auc: 0.9806 - loss: 0.1553 - prec: 0.9065 - rec: 0.8945 - val_auc: 0.9830 - val_loss: 0.1591 - val_prec: 0.8616 - val_rec: 0.9421 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 60ms/step - auc: 0.9810 - loss: 0.1541 - prec: 0.9017 - rec: 0.8931 - val_auc: 0.9840 - val_loss: 0.1603 - val_prec: 0.8638 - val_rec: 0.9427 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 61ms/step - auc: 0.9822 - loss: 0.1491 - prec: 0.9085 - rec: 0.8979 - val_auc: 0.9827 - val_loss: 0.1512 - val_prec: 0.9306 - val_rec: 0.8722 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 61ms/step - auc: 0.9833 - loss: 0.1442 - prec: 0.9112 - rec: 0.9017 - val_auc: 0.9830 - val_loss: 0.1608 - val_prec: 0.9406 - val_rec: 0.8351 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - auc: 0.9858 - loss: 0.1322 - prec: 0.9200 - rec: 0.9107 - val_auc: 0.9869 - val_loss: 0.1334 - val_prec: 0.8896 - val_rec: 0.9400 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - auc: 0.9864 - loss: 0.1287 - prec: 0.9224 - rec: 0.9155 - val_auc: 0.9861 - val_loss: 0.1379 - val_prec: 0.8869 - val_rec: 0.9421 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 63ms/step - auc: 0.9868 - loss: 0.1271 - prec: 0.9228 - rec: 0.9163 - val_auc: 0.9864 - val_loss: 0.1315 - val_prec: 0.9330 - val_rec: 0.8949 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 63ms/step - auc: 0.9883 - loss: 0.1186 - prec: 0.9293 - rec: 0.9237 - val_auc: 0.9868 - val_loss: 0.1334 - val_prec: 0.9421 - val_rec: 0.8762 - learning_rate: 2.5000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 64ms/step - auc: 0.9882 - loss: 0.1188 - prec: 0.9280 - rec: 0.9208 - val_auc: 0.9879 - val_loss: 0.1232 - val_prec: 0.9258 - val_rec: 0.9125 - learning_rate: 2.5000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 62ms/step - auc: 0.9886 - loss: 0.1159 - prec: 0.9295 - rec: 0.9230 - val_auc: 0.9876 - val_loss: 0.1256 - val_prec: 0.9253 - val_rec: 0.9043 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 65ms/step - auc: 0.9892 - loss: 0.1147 - prec: 0.9313 - rec: 0.9254 - val_auc: 0.9870 - val_loss: 0.1255 - val_prec: 0.9106 - val_rec: 0.9303 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 69ms/step - auc: 0.9895 - loss: 0.1117 - prec: 0.9328 - rec: 0.9299 - val_auc: 0.9874 - val_loss: 0.1267 - val_prec: 0.9233 - val_rec: 0.9131 - learning_rate: 1.2500e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - auc: 0.9899 - loss: 0.1102 - prec: 0.9334 - rec: 0.9292 - val_auc: 0.9870 - val_loss: 0.1258 - val_prec: 0.9116 - val_rec: 0.9242 - learning_rate: 1.2500e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 74ms/step - auc: 0.9900 - loss: 0.1084 - prec: 0.9368 - rec: 0.9312 - val_auc: 0.9878 - val_loss: 0.1221 - val_prec: 0.9164 - val_rec: 0.9286 - learning_rate: 6.2500e-05\n",
      "Epoch 36/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 72ms/step - auc: 0.9898 - loss: 0.1091 - prec: 0.9337 - rec: 0.9312 - val_auc: 0.9877 - val_loss: 0.1220 - val_prec: 0.9254 - val_rec: 0.9131 - learning_rate: 6.2500e-05\n",
      "saved best: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\v4_model_best.keras\n",
      "saved last: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\v4_model_last.keras\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# memmap read 모드로 재오픈\n",
    "X_mm = np.memmap(str(X_PATH), dtype=\"float32\", mode=\"r\", shape=(N_TOTAL, FRAMES, N_MELS))\n",
    "st = np.load(str(STATS_PATH))\n",
    "mu = st[\"mu\"].astype(np.float32)\n",
    "sd = st[\"sd\"].astype(np.float32)\n",
    "\n",
    "BATCH = int(cfg[\"training\"][\"batch_size\"])\n",
    "\n",
    "sa = cfg[\"augment\"][\"specaugment\"]\n",
    "SA_PROB = float(sa[\"apply_prob\"])\n",
    "SA_TM = int(sa[\"time_masks\"])\n",
    "SA_TMAX = int(sa[\"time_mask_max\"])\n",
    "SA_FM = int(sa[\"freq_masks\"])\n",
    "SA_FMAX = int(sa[\"freq_mask_max\"])\n",
    "\n",
    "def specaugment_np(f):\n",
    "    g = f.copy()\n",
    "    T, F = g.shape\n",
    "    for _ in range(SA_TM):\n",
    "        w = np.random.randint(0, SA_TMAX+1)\n",
    "        if w > 0 and T - w > 0:\n",
    "            t0 = np.random.randint(0, T - w)\n",
    "            g[t0:t0+w, :] = 0.0\n",
    "    for _ in range(SA_FM):\n",
    "        w = np.random.randint(0, SA_FMAX+1)\n",
    "        if w > 0 and F - w > 0:\n",
    "            f0 = np.random.randint(0, F - w)\n",
    "            g[:, f0:f0+w] = 0.0\n",
    "    return g\n",
    "\n",
    "def batch_generator(idxs, shuffle=True):\n",
    "    idxs = np.array(idxs, dtype=np.int64)\n",
    "    n = len(idxs)\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        for s in range(0, n, BATCH):\n",
    "            b = idxs[s:s+BATCH]\n",
    "            Xb = np.array(X_mm[b, :, :], dtype=np.float32)\n",
    "            Xb = (Xb - mu[None, None, :]) / (sd[None, None, :] + 1e-6)\n",
    "\n",
    "            if np.random.rand() < SA_PROB:\n",
    "                for i in range(Xb.shape[0]):\n",
    "                    Xb[i] = specaugment_np(Xb[i])\n",
    "\n",
    "            Xb = Xb[..., None]\n",
    "            yb = y_all[b].astype(np.float32)\n",
    "            yield Xb, yb\n",
    "\n",
    "def build_model(frames, mels):\n",
    "    inp = tf.keras.Input(shape=(frames, mels, 1))\n",
    "    x = tf.keras.layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "BEST_PATH = OUT / \"v4_model_best.keras\"\n",
    "LAST_PATH = OUT / \"v4_model_last.keras\"\n",
    "\n",
    "# 재개: last가 있으면 로드, 없으면 새로 생성\n",
    "if LAST_PATH.exists():\n",
    "    print(\"resume from:\", LAST_PATH)\n",
    "    model = tf.keras.models.load_model(str(LAST_PATH))\n",
    "else:\n",
    "    model = build_model(FRAMES, N_MELS)\n",
    "\n",
    "lr = float(cfg[\"training\"][\"lr\"])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Precision(name=\"prec\"), tf.keras.metrics.Recall(name=\"rec\")]\n",
    ")\n",
    "\n",
    "steps_per_epoch = math.ceil(len(idx_train) / BATCH)\n",
    "val_steps = math.ceil(len(idx_val) / BATCH)\n",
    "\n",
    "train_gen = batch_generator(idx_train, shuffle=True)\n",
    "val_gen   = batch_generator(idx_val, shuffle=False)\n",
    "\n",
    "cbs = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(str(BEST_PATH), monitor=\"val_auc\", mode=\"max\", save_best_only=True, save_weights_only=False),\n",
    "    tf.keras.callbacks.ModelCheckpoint(str(LAST_PATH), monitor=\"val_auc\", mode=\"max\", save_best_only=False, save_weights_only=False),\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=int(cfg[\"training\"][\"early_stopping_patience\"]), restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", patience=int(cfg[\"training\"][\"reduce_lr_patience\"]), factor=float(cfg[\"training\"][\"reduce_lr_factor\"])),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=int(cfg[\"training\"][\"epochs\"]),   # 100 상한, early stopping이 알아서 멈춤\n",
    "    callbacks=cbs,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"saved best:\", BEST_PATH)\n",
    "print(\"saved last:\", LAST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4d3396f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion @0.5:\n",
      " [[4385  116]\n",
      " [ 139 1661]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9693    0.9742    0.9717      4501\n",
      "           1     0.9347    0.9228    0.9287      1800\n",
      "\n",
      "    accuracy                         0.9595      6301\n",
      "   macro avg     0.9520    0.9485    0.9502      6301\n",
      "weighted avg     0.9594    0.9595    0.9595      6301\n",
      "\n",
      "threshold: 0.9609946 saved: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\v4_threshold.txt\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\hmchung\\AppData\\Local\\Temp\\tmp3_yjf0gc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\hmchung\\AppData\\Local\\Temp\\tmp3_yjf0gc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at 'C:\\Users\\hmchung\\AppData\\Local\\Temp\\tmp3_yjf0gc'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 198, 64, 1), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  2299665620944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2299665622672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2299665622096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2299665621520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2299665623056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2299665622864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2297362909712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2297362908944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2297362910672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  2297362910288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "saved: c:\\Dev\\sneezing_detection\\legacy_code\\out\\v4\\v4_model.tflite bytes: 34472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve\n",
    "\n",
    "best_model = tf.keras.models.load_model(str(BEST_PATH))\n",
    "\n",
    "def predict_on_idxs(idxs):\n",
    "    probs, ys = [], []\n",
    "    for s in range(0, len(idxs), BATCH):\n",
    "        b = np.array(idxs[s:s+BATCH], dtype=np.int64)\n",
    "        Xb = np.array(X_mm[b, :, :], dtype=np.float32)\n",
    "        Xb = (Xb - mu[None, None, :]) / (sd[None, None, :] + 1e-6)\n",
    "        Xb = Xb[..., None]\n",
    "        pb = best_model.predict(Xb, verbose=0).reshape(-1)\n",
    "        probs.append(pb)\n",
    "        ys.append(y_all[b])\n",
    "    return np.concatenate(probs), np.concatenate(ys)\n",
    "\n",
    "p_test, y_test2 = predict_on_idxs(idx_test)\n",
    "thr = 0.5\n",
    "yhat = (p_test >= thr).astype(int)\n",
    "\n",
    "print(\"confusion @0.5:\\n\", confusion_matrix(y_test2, yhat))\n",
    "print(classification_report(y_test2, yhat, digits=4))\n",
    "\n",
    "p_val, y_val2 = predict_on_idxs(idx_val)\n",
    "prec, rec, th = precision_recall_curve(y_val2, p_val)\n",
    "\n",
    "target_prec = float(cfg[\"thresholding\"][\"target_precision\"])\n",
    "fallback = float(cfg[\"thresholding\"][\"fallback_threshold\"])\n",
    "\n",
    "cands = [(t, p, r) for t, p, r in zip(th, prec[:-1], rec[:-1]) if p >= target_prec]\n",
    "if len(cands) == 0:\n",
    "    best_t = fallback\n",
    "else:\n",
    "    best_t, _, _ = sorted(cands, key=lambda x: x[2], reverse=True)[0]\n",
    "\n",
    "THR_PATH = OUT / \"v4_threshold.txt\"\n",
    "THR_PATH.write_text(f\"{best_t}\\n\", encoding=\"utf-8\")\n",
    "print(\"threshold:\", best_t, \"saved:\", THR_PATH)\n",
    "\n",
    "# TFLite 변환(동적 양자화)\n",
    "TFLITE_PATH = OUT / \"v4_model.tflite\"\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(best_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "tflite_model = converter.convert()\n",
    "TFLITE_PATH.write_bytes(tflite_model)\n",
    "print(\"saved:\", TFLITE_PATH, \"bytes:\", TFLITE_PATH.stat().st_size)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sneeze-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
