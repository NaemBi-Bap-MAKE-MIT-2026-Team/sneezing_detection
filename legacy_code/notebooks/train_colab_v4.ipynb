{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "547335f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install librosa soundfile tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12c4fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, random, shutil, time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "999d6923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "631a40f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVE_SNEEZE exists: True /content/drive/MyDrive/sneeze_models\n",
      "ZIP exists: True /content/drive/MyDrive/raw_data.zip\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
    "DRIVE_SNEEZE = DRIVE_ROOT / \"sneeze_models\"          # 드라이브에 있는 sneeze_model 폴더\n",
    "ZIP_PATH = DRIVE_ROOT / \"raw_data.zip\"      # 효민님이 새로 만든 zip 파일명으로 맞추기\n",
    "\n",
    "print(\"DRIVE_SNEEZE exists:\", DRIVE_SNEEZE.exists(), DRIVE_SNEEZE)\n",
    "print(\"ZIP exists:\", ZIP_PATH.exists(), ZIP_PATH)\n",
    "\n",
    "# 필수 체크\n",
    "assert DRIVE_SNEEZE.exists(), \"드라이브의 sneeze_model 폴더 경로가 틀렸습니다. DRIVE_SNEEZE를 수정하십시오.\"\n",
    "assert ZIP_PATH.exists(), \"zip 경로가 틀렸습니다. ZIP_PATH를 수정하십시오.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70f4b9d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORK exists: True\n",
      "WORK contents:\n",
      " - /content/work/MS-SNSD-NOISE (dir)\n",
      " - /content/work/esc-50 (dir)\n",
      " - /content/work/recordings (dir)\n",
      " - /content/work/sneeze (dir)\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "WORK = Path(\"/content/work\")\n",
    "\n",
    "# zip 풀기\n",
    "!unzip -q \"{ZIP_PATH}\" -d \"{WORK}\"\n",
    "\n",
    "print(\"WORK exists:\", WORK.exists())\n",
    "print(\"WORK contents:\")\n",
    "for p in sorted(WORK.iterdir()):\n",
    "    print(\" -\", p, \"(dir)\" if p.is_dir() else \"(file)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a979116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK: /content/work/esc-50\n",
      "OK: /content/work/MS-SNSD-NOISE\n",
      "OK: /content/work/sneeze\n",
      "OK: /content/work/recordings\n"
     ]
    }
   ],
   "source": [
    "WORK = Path(\"/content/work\")\n",
    "\n",
    "ESC50_DIR   = WORK / \"esc-50\"\n",
    "MS_SNSD_DIR = WORK / \"MS-SNSD-NOISE\"\n",
    "SNEEZE_DIR  = WORK / \"sneeze\"\n",
    "REC_DIR     = WORK / \"recordings\"\n",
    "\n",
    "assert ESC50_DIR.exists(), ESC50_DIR\n",
    "assert MS_SNSD_DIR.exists(), MS_SNSD_DIR\n",
    "assert SNEEZE_DIR.exists(), SNEEZE_DIR\n",
    "assert REC_DIR.exists(), REC_DIR\n",
    "\n",
    "print(\"OK:\", ESC50_DIR)\n",
    "print(\"OK:\", MS_SNSD_DIR)\n",
    "print(\"OK:\", SNEEZE_DIR)\n",
    "print(\"OK:\", REC_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89be9b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esc-50\tMS-SNSD-NOISE  recordings  sneeze\n"
     ]
    }
   ],
   "source": [
    "!ls /content/work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41fc99af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config loaded: v4 at /content/work/config_v4.json\n"
     ]
    }
   ],
   "source": [
    "CONFIG_PATH = WORK / \"config_v4.json\"\n",
    "\n",
    "config_text = r'''\n",
    "{\n",
    "  \"version\": \"v4\",\n",
    "  \"seed\": 1337,\n",
    "\n",
    "  \"audio\": {\n",
    "    \"sr\": 16000,\n",
    "    \"clip_seconds\": 2.0\n",
    "  },\n",
    "\n",
    "  \"features\": {\n",
    "    \"type\": \"logmel\",\n",
    "    \"n_mels\": 64,\n",
    "    \"n_fft\": 400,\n",
    "    \"hop_length\": 160,\n",
    "    \"center\": false,\n",
    "    \"log_eps\": 1e-6\n",
    "  },\n",
    "\n",
    "  \"normalization\": {\n",
    "    \"mode\": \"dataset_stats\",\n",
    "    \"rms_target_range\": [0.03, 0.15],\n",
    "    \"rms_apply_prob\": 1.0\n",
    "  },\n",
    "\n",
    "  \"dataset_sizes\": {\n",
    "    \"pos_total\": 12000,\n",
    "    \"neg_total\": 30000,\n",
    "    \"pos_mix_ratio\": 0.70\n",
    "  },\n",
    "\n",
    "  \"negative_plan\": {\n",
    "    \"event_ratio\": 0.60,\n",
    "    \"background_ratio\": 0.40,\n",
    "\n",
    "    \"event_sources\": {\n",
    "      \"esc50_excluding_sneeze\": 0.40,\n",
    "      \"yaho\": 0.35,\n",
    "      \"noise1_noise2\": 0.25\n",
    "    },\n",
    "\n",
    "    \"background_sources\": {\n",
    "      \"ms_snsd\": 0.50,\n",
    "      \"talk\": 0.30,\n",
    "      \"dish\": 0.20\n",
    "    }\n",
    "  },\n",
    "\n",
    "  \"positive_plan\": {\n",
    "    \"original_ratio\": 0.30,\n",
    "    \"synthetic_ratio\": 0.70,\n",
    "\n",
    "    \"background_pool\": {\n",
    "      \"ms_snsd\": 0.40,\n",
    "      \"talk\": 0.40,\n",
    "      \"dish\": 0.20\n",
    "    },\n",
    "\n",
    "    \"snr_db_range_bg\": [0.0, 20.0],\n",
    "\n",
    "    \"optional_event_on_pos\": {\n",
    "      \"apply_prob\": 0.15,\n",
    "      \"event_pool\": {\n",
    "        \"yaho\": 0.50,\n",
    "        \"esc50_excluding_sneeze\": 0.30,\n",
    "        \"noise1_noise2\": 0.20\n",
    "      },\n",
    "      \"snr_db_range_event\": [15.0, 30.0]\n",
    "    }\n",
    "  },\n",
    "\n",
    "  \"augment\": {\n",
    "    \"gain_db_range\": [-6.0, 6.0],\n",
    "    \"time_shift_ms\": 200,\n",
    "\n",
    "    \"reverb\": {\n",
    "      \"apply_prob\": 0.10,\n",
    "      \"ir_seconds_range\": [0.05, 0.25],\n",
    "      \"mix_range\": [0.02, 0.10]\n",
    "    },\n",
    "\n",
    "    \"time_stretch\": {\n",
    "      \"apply_prob\": 0.10,\n",
    "      \"rate_range\": [0.95, 1.05]\n",
    "    },\n",
    "\n",
    "    \"pitch_shift\": {\n",
    "      \"apply_prob\": 0.05,\n",
    "      \"semitones_range\": [-0.25, 0.25]\n",
    "    },\n",
    "\n",
    "    \"specaugment\": {\n",
    "      \"apply_prob\": 0.20,\n",
    "      \"time_masks\": 1,\n",
    "      \"time_mask_max\": 12,\n",
    "      \"freq_masks\": 1,\n",
    "      \"freq_mask_max\": 6\n",
    "    }\n",
    "  },\n",
    "\n",
    "  \"splits\": {\n",
    "    \"train\": 0.70,\n",
    "    \"val\": 0.15,\n",
    "    \"test\": 0.15\n",
    "  },\n",
    "\n",
    "  \"training\": {\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 25,\n",
    "    \"lr\": 0.001,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    \"reduce_lr_patience\": 2,\n",
    "    \"reduce_lr_factor\": 0.5\n",
    "  },\n",
    "\n",
    "  \"thresholding\": {\n",
    "    \"method\": \"precision_target\",\n",
    "    \"target_precision\": 0.99,\n",
    "    \"fallback_threshold\": 0.90\n",
    "  },\n",
    "\n",
    "  \"export\": {\n",
    "    \"tflite_dynamic\": true\n",
    "  }\n",
    "}\n",
    "'''\n",
    "CONFIG_PATH.write_text(config_text, encoding=\"utf-8\")\n",
    "\n",
    "cfg = json.loads(CONFIG_PATH.read_text(encoding=\"utf-8\"))\n",
    "print(\"config loaded:\", cfg[\"version\"], \"at\", CONFIG_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c5096c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f477dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1337\n"
     ]
    }
   ],
   "source": [
    "SEED = int(cfg[\"seed\"])\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "print(\"seed:\", SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f5eb18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sneeze clips: 968\n",
      "esc-50 event files(excl sneeze): 2000\n",
      "ms-snsd wav files: 128\n"
     ]
    }
   ],
   "source": [
    "SR = int(cfg[\"audio\"][\"sr\"])\n",
    "CLIP_SEC = float(cfg[\"audio\"][\"clip_seconds\"])\n",
    "CLIP_SAMPLES = int(SR * CLIP_SEC)\n",
    "\n",
    "# recordings\n",
    "TALK_WAV  = REC_DIR / \"talk.wav\"\n",
    "DISH_WAV  = REC_DIR / \"dish.wav\"\n",
    "YAHO_WAV  = REC_DIR / \"yaho.wav\"\n",
    "NOISE1_WAV = REC_DIR / \"noise1.wav\"\n",
    "NOISE2_WAV = REC_DIR / \"noise2.wav\"\n",
    "\n",
    "for p in [TALK_WAV, DISH_WAV, YAHO_WAV, NOISE1_WAV, NOISE2_WAV]:\n",
    "    assert p.exists(), f\"missing: {p}\"\n",
    "\n",
    "# sneeze clips\n",
    "sneeze_files = sorted([p for p in SNEEZE_DIR.rglob(\"*.wav\")])\n",
    "assert len(sneeze_files) > 0\n",
    "print(\"sneeze clips:\", len(sneeze_files))\n",
    "\n",
    "# ESC-50: meta로 sneeze 클래스 제외\n",
    "esc_meta = ESC50_DIR / \"meta\" / \"esc50.csv\"\n",
    "esc_audio_dir = ESC50_DIR / \"audio\"\n",
    "assert esc_meta.exists(), esc_meta\n",
    "assert esc_audio_dir.exists(), esc_audio_dir\n",
    "\n",
    "import csv\n",
    "esc_rows = []\n",
    "with open(esc_meta, \"r\", encoding=\"utf-8\") as f:\n",
    "    r = csv.DictReader(f)\n",
    "    for row in r:\n",
    "        esc_rows.append(row)\n",
    "\n",
    "# ESC-50 라벨 문자열에 'sneeze'가 있으면 제외\n",
    "esc_event_files = []\n",
    "for row in esc_rows:\n",
    "    label = row[\"category\"].strip().lower()\n",
    "    fname = row[\"filename\"].strip()\n",
    "    if \"sneeze\" in label:\n",
    "        continue\n",
    "    wav = esc_audio_dir / fname\n",
    "    if wav.exists():\n",
    "        esc_event_files.append(wav)\n",
    "\n",
    "print(\"esc-50 event files(excl sneeze):\", len(esc_event_files))\n",
    "\n",
    "# MS-SNSD: wav 전부 수집\n",
    "ms_snsd_files = sorted([p for p in MS_SNSD_DIR.rglob(\"*.wav\")])\n",
    "assert len(ms_snsd_files) > 0\n",
    "print(\"ms-snsd wav files:\", len(ms_snsd_files))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48ac5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rms(x):\n",
    "    x = np.asarray(x, np.float32)\n",
    "    return float(np.sqrt(np.mean(x*x) + 1e-8))\n",
    "\n",
    "def fix_2s(y):\n",
    "    y = np.asarray(y, np.float32)\n",
    "    if len(y) >= CLIP_SAMPLES:\n",
    "        return y[:CLIP_SAMPLES]\n",
    "    return np.pad(y, (0, CLIP_SAMPLES - len(y))).astype(np.float32)\n",
    "\n",
    "def rand_crop_2s(y):\n",
    "    y = np.asarray(y, np.float32)\n",
    "    if len(y) <= CLIP_SAMPLES:\n",
    "        return fix_2s(y)\n",
    "    start = np.random.randint(0, len(y) - CLIP_SAMPLES + 1)\n",
    "    return y[start:start+CLIP_SAMPLES].astype(np.float32)\n",
    "\n",
    "def load_mono(path, sr=SR):\n",
    "    y, _ = librosa.load(str(path), sr=sr, mono=True)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def apply_gain_db(y, db):\n",
    "    g = 10 ** (db / 20.0)\n",
    "    return np.clip(y * g, -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def rms_randomize(y, lo, hi):\n",
    "    target = float(np.random.uniform(lo, hi))\n",
    "    r = rms(y)\n",
    "    if r > 1e-6:\n",
    "        y = y * (target / (r + 1e-8))\n",
    "    return np.clip(y, -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def mix_at_snr(signal, background, snr_db):\n",
    "    s = np.asarray(signal, np.float32)\n",
    "    b = np.asarray(background, np.float32)\n",
    "\n",
    "    s = fix_2s(s)\n",
    "    b = fix_2s(b)\n",
    "\n",
    "    rs = rms(s)\n",
    "    rb = rms(b)\n",
    "    if rb < 1e-6:\n",
    "        return s\n",
    "\n",
    "    # 원하는 SNR: 20*log10(rs / (rb*alpha)) = snr_db  -> alpha = rs / (rb * 10^(snr/20))\n",
    "    alpha = (rs + 1e-8) / ((rb + 1e-8) * (10 ** (snr_db / 20.0)))\n",
    "    y = s + b * alpha\n",
    "    return np.clip(y, -1.0, 1.0).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b1c01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(y, max_ms=200):\n",
    "    max_samp = int(SR * (max_ms / 1000.0))\n",
    "    if max_samp <= 0:\n",
    "        return y\n",
    "    k = np.random.randint(-max_samp, max_samp + 1)\n",
    "    return np.roll(y, k).astype(np.float32)\n",
    "\n",
    "def maybe_time_stretch(y, prob, r_lo, r_hi):\n",
    "    if np.random.rand() > prob:\n",
    "        return y\n",
    "    rate = float(np.random.uniform(r_lo, r_hi))\n",
    "    # librosa time_stretch는 길이가 변함 -> 다시 2초로 맞춤\n",
    "    ys = librosa.effects.time_stretch(y, rate=rate).astype(np.float32)\n",
    "    return fix_2s(ys)\n",
    "\n",
    "def maybe_pitch_shift(y, prob, s_lo, s_hi):\n",
    "    if np.random.rand() > prob:\n",
    "        return y\n",
    "    steps = float(np.random.uniform(s_lo, s_hi))\n",
    "    yp = librosa.effects.pitch_shift(y, sr=SR, n_steps=steps).astype(np.float32)\n",
    "    return fix_2s(yp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3cb4ce6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_MELS = int(cfg[\"features\"][\"n_mels\"])\n",
    "N_FFT  = int(cfg[\"features\"][\"n_fft\"])\n",
    "HOP    = int(cfg[\"features\"][\"hop_length\"])\n",
    "CENTER = bool(cfg[\"features\"][\"center\"])\n",
    "LOG_EPS = float(cfg[\"features\"][\"log_eps\"])\n",
    "\n",
    "def logmel(y):\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=N_FFT, hop_length=HOP,\n",
    "        n_mels=N_MELS, power=2.0, center=CENTER\n",
    "    )\n",
    "    return np.log(S + LOG_EPS).T.astype(np.float32)  # (frames, mels)\n",
    "\n",
    "def specaugment(f, time_masks=1, tmax=12, freq_masks=1, fmax=6):\n",
    "    g = f.copy()\n",
    "    T, F = g.shape\n",
    "    for _ in range(time_masks):\n",
    "        w = np.random.randint(0, tmax+1)\n",
    "        if w == 0: \n",
    "            continue\n",
    "        t0 = np.random.randint(0, max(1, T - w))\n",
    "        g[t0:t0+w, :] = 0.0\n",
    "    for _ in range(freq_masks):\n",
    "        w = np.random.randint(0, fmax+1)\n",
    "        if w == 0:\n",
    "            continue\n",
    "        f0 = np.random.randint(0, max(1, F - w))\n",
    "        g[:, f0:f0+w] = 0.0\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb8645f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 긴 recordings에서 랜덤 2초 크롭\n",
    "talk_audio = load_mono(TALK_WAV)\n",
    "dish_audio = load_mono(DISH_WAV)\n",
    "yaho_audio = load_mono(YAHO_WAV)\n",
    "noise1_audio = load_mono(NOISE1_WAV)\n",
    "noise2_audio = load_mono(NOISE2_WAV)\n",
    "\n",
    "def sample_from_long(y_long):\n",
    "    return rand_crop_2s(y_long)\n",
    "\n",
    "def sample_esc50_2s(path):\n",
    "    y = load_mono(path)\n",
    "    return rand_crop_2s(y)\n",
    "\n",
    "def sample_ms_snsd_2s(path):\n",
    "    y = load_mono(path)\n",
    "    return rand_crop_2s(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a13d1101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FRAMES: 198 N_MELS: 64 N_TOTAL: 42000\n",
      "memmap X: /content/work/out/v4/v4_features_f32.dat\n",
      "memmap y: /content/work/out/v4/v4_labels_i8.dat\n",
      "pos_total: 12000 original: 3600 synth: 8400\n",
      "neg_total: 30000 event: 18000 bg: 12000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pos_original: 100%|██████████| 3600/3600 [00:32<00:00, 109.24it/s]\n",
      "pos_synth: 100%|██████████| 8400/8400 [02:05<00:00, 67.12it/s] \n",
      "neg_bg: 100%|██████████| 12000/12000 [02:57<00:00, 67.72it/s] \n",
      "neg_event: 100%|██████████| 18000/18000 [04:20<00:00, 69.07it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "written samples: 42000 expected: 42000\n",
      "pos: 12000 neg: 30000\n",
      "count_tf(frames): 8316000 expected: 8316000\n",
      "saved meta: /content/work/out/v4/v4_meta.json\n"
     ]
    }
   ],
   "source": [
    "# v4 OUT_DIR 준비\n",
    "OUT_DIR = WORK / \"out\" / \"v4\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pos_total = int(cfg[\"dataset_sizes\"][\"pos_total\"])\n",
    "neg_total = int(cfg[\"dataset_sizes\"][\"neg_total\"])\n",
    "N_TOTAL = pos_total + neg_total\n",
    "\n",
    "# frames를 확정(2초 고정 + center 고정이므로 frames 고정)\n",
    "tmp = logmel(np.zeros(CLIP_SAMPLES, np.float32))\n",
    "FRAMES = int(tmp.shape[0])\n",
    "assert tmp.shape[1] == N_MELS\n",
    "print(\"FRAMES:\", FRAMES, \"N_MELS:\", N_MELS, \"N_TOTAL:\", N_TOTAL)\n",
    "\n",
    "# memmap 경로\n",
    "X_PATH = OUT_DIR / \"v4_features_f32.dat\"\n",
    "Y_PATH = OUT_DIR / \"v4_labels_i8.dat\"\n",
    "META_PATH = OUT_DIR / \"v4_meta.json\"\n",
    "\n",
    "# memmap 할당\n",
    "X_mm = np.memmap(str(X_PATH), dtype=\"float32\", mode=\"w+\", shape=(N_TOTAL, FRAMES, N_MELS))\n",
    "y_mm = np.memmap(str(Y_PATH), dtype=\"int8\", mode=\"w+\", shape=(N_TOTAL,))\n",
    "\n",
    "print(\"memmap X:\", X_PATH)\n",
    "print(\"memmap y:\", Y_PATH)\n",
    "\n",
    "# 통계 누적(멜 bin별, 모든 프레임/샘플 전체에 대해)\n",
    "sum_m = np.zeros((N_MELS,), np.float64)\n",
    "sumsq_m = np.zeros((N_MELS,), np.float64)\n",
    "count_tf = 0  # total frames count (N * FRAMES)\n",
    "\n",
    "# 구성 수치\n",
    "pos_original_n = int(pos_total * float(cfg[\"positive_plan\"][\"original_ratio\"]))\n",
    "pos_synth_n    = pos_total - pos_original_n\n",
    "\n",
    "neg_event_n = int(neg_total * float(cfg[\"negative_plan\"][\"event_ratio\"]))\n",
    "neg_bg_n    = neg_total - neg_event_n\n",
    "\n",
    "print(\"pos_total:\", pos_total, \"original:\", pos_original_n, \"synth:\", pos_synth_n)\n",
    "print(\"neg_total:\", neg_total, \"event:\", neg_event_n, \"bg:\", neg_bg_n)\n",
    "\n",
    "def write_feature(i, y_audio, label):\n",
    "    global sum_m, sumsq_m, count_tf\n",
    "    f = logmel(y_audio)  # (frames, 64)\n",
    "    # 혹시라도 파라미터 변경/라이브러리 차이로 frames가 달라지면 강제로 맞춤\n",
    "    if f.shape[0] > FRAMES:\n",
    "        f = f[:FRAMES, :]\n",
    "    elif f.shape[0] < FRAMES:\n",
    "        f = np.pad(f, ((0, FRAMES - f.shape[0]), (0, 0)), mode=\"constant\")\n",
    "\n",
    "    # specaugment는 저장 단계에서 하지 말고, 학습 단계에서 on-the-fly로 하는 편이 안정적입니다.\n",
    "    # 여기서는 feature 고정(재현성 + 디버깅)\n",
    "    X_mm[i, :, :] = f.astype(np.float32)\n",
    "    y_mm[i] = np.int8(label)\n",
    "\n",
    "    # 통계 누적(멜별로 프레임 합산)\n",
    "    sum_m += f.sum(axis=0)\n",
    "    sumsq_m += (f * f).sum(axis=0)\n",
    "    count_tf += f.shape[0]\n",
    "\n",
    "# 가중치 선택(기존 셀 10의 weighted_choice 그대로 사용 가능)\n",
    "def weighted_choice(items, weights):\n",
    "    w = np.asarray(weights, np.float64)\n",
    "    w = w / w.sum()\n",
    "    idx = np.random.choice(len(items), p=w)\n",
    "    return items[idx]\n",
    "\n",
    "# 풀/가중치(기존 계획 그대로)\n",
    "bg_pool_items = [\"ms_snsd\", \"talk\", \"dish\"]\n",
    "bg_pool_w = [\n",
    "    cfg[\"positive_plan\"][\"background_pool\"][\"ms_snsd\"],\n",
    "    cfg[\"positive_plan\"][\"background_pool\"][\"talk\"],\n",
    "    cfg[\"positive_plan\"][\"background_pool\"][\"dish\"],\n",
    "]\n",
    "\n",
    "pos_evt_items = [\"yaho\", \"esc\", \"noise12\"]\n",
    "pos_evt_w = [\n",
    "    cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"event_pool\"][\"yaho\"],\n",
    "    cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"event_pool\"][\"esc50_excluding_sneeze\"],\n",
    "    cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"event_pool\"][\"noise1_noise2\"],\n",
    "]\n",
    "\n",
    "neg_evt_items = [\"esc\", \"yaho\", \"noise12\"]\n",
    "neg_evt_w = [\n",
    "    cfg[\"negative_plan\"][\"event_sources\"][\"esc50_excluding_sneeze\"],\n",
    "    cfg[\"negative_plan\"][\"event_sources\"][\"yaho\"],\n",
    "    cfg[\"negative_plan\"][\"event_sources\"][\"noise1_noise2\"],\n",
    "]\n",
    "\n",
    "neg_bg_items = [\"ms_snsd\", \"talk\", \"dish\"]\n",
    "neg_bg_w = [\n",
    "    cfg[\"negative_plan\"][\"background_sources\"][\"ms_snsd\"],\n",
    "    cfg[\"negative_plan\"][\"background_sources\"][\"talk\"],\n",
    "    cfg[\"negative_plan\"][\"background_sources\"][\"dish\"],\n",
    "]\n",
    "\n",
    "rms_lo, rms_hi = cfg[\"normalization\"][\"rms_target_range\"]\n",
    "snr_bg_lo, snr_bg_hi = cfg[\"positive_plan\"][\"snr_db_range_bg\"]\n",
    "pos_evt_prob = float(cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"apply_prob\"])\n",
    "snr_evt_lo, snr_evt_hi = cfg[\"positive_plan\"][\"optional_event_on_pos\"][\"snr_db_range_event\"]\n",
    "\n",
    "aug = cfg[\"augment\"]\n",
    "gain_lo, gain_hi = aug[\"gain_db_range\"]\n",
    "shift_ms = int(aug[\"time_shift_ms\"])\n",
    "ts_prob = float(aug[\"time_stretch\"][\"apply_prob\"])\n",
    "ts_lo, ts_hi = aug[\"time_stretch\"][\"rate_range\"]\n",
    "ps_prob = float(aug[\"pitch_shift\"][\"apply_prob\"])\n",
    "ps_lo, ps_hi = aug[\"pitch_shift\"][\"semitones_range\"]\n",
    "\n",
    "def sample_background(source_name):\n",
    "    if source_name == \"talk\":\n",
    "        return sample_from_long(talk_audio)\n",
    "    if source_name == \"dish\":\n",
    "        return sample_from_long(dish_audio)\n",
    "    if source_name == \"ms_snsd\":\n",
    "        p = random.choice(ms_snsd_files)\n",
    "        return sample_ms_snsd_2s(p)\n",
    "    raise ValueError(source_name)\n",
    "\n",
    "def sample_event(source_name):\n",
    "    if source_name == \"yaho\":\n",
    "        return sample_from_long(yaho_audio)\n",
    "    if source_name == \"noise12\":\n",
    "        return sample_from_long(noise1_audio if np.random.rand() < 0.5 else noise2_audio)\n",
    "    if source_name == \"esc\":\n",
    "        p = random.choice(esc_event_files)\n",
    "        return sample_esc50_2s(p)\n",
    "    raise ValueError(source_name)\n",
    "\n",
    "def apply_audio_aug(y):\n",
    "    # gain\n",
    "    y = apply_gain_db(y, float(np.random.uniform(gain_lo, gain_hi)))\n",
    "    # shift\n",
    "    y = time_shift(y, max_ms=shift_ms)\n",
    "    # stretch/pitch (약하게)\n",
    "    y = maybe_time_stretch(y, ts_prob, ts_lo, ts_hi)\n",
    "    y = maybe_pitch_shift(y, ps_prob, ps_lo, ps_hi)\n",
    "    # RMS 랜덤화(레벨 변화 학습)\n",
    "    y = rms_randomize(y, rms_lo, rms_hi)\n",
    "    return y\n",
    "\n",
    "# 생성 루프\n",
    "i = 0\n",
    "\n",
    "# 포지: 원본\n",
    "for _ in tqdm(range(pos_original_n), desc=\"pos_original\"):\n",
    "    p = random.choice(sneeze_files)\n",
    "    y = rand_crop_2s(load_mono(p))\n",
    "    y = apply_audio_aug(y)\n",
    "    write_feature(i, y, 1)\n",
    "    i += 1\n",
    "\n",
    "# 포지: 합성(재채기 + 배경, 가끔 이벤트 약하게)\n",
    "for _ in tqdm(range(pos_synth_n), desc=\"pos_synth\"):\n",
    "    p = random.choice(sneeze_files)\n",
    "    sneeze = rand_crop_2s(load_mono(p))\n",
    "\n",
    "    bg_src = weighted_choice(bg_pool_items, bg_pool_w)\n",
    "    bg = sample_background(bg_src)\n",
    "\n",
    "    snr_bg = float(np.random.uniform(snr_bg_lo, snr_bg_hi))\n",
    "    y = mix_at_snr(sneeze, bg, snr_bg)\n",
    "\n",
    "    if np.random.rand() < pos_evt_prob:\n",
    "        evt_src = weighted_choice(pos_evt_items, pos_evt_w)\n",
    "        evt = sample_event(evt_src)\n",
    "        snr_evt = float(np.random.uniform(snr_evt_lo, snr_evt_hi))\n",
    "        y = mix_at_snr(y, evt, snr_evt)\n",
    "\n",
    "    y = apply_audio_aug(y)\n",
    "    write_feature(i, y, 1)\n",
    "    i += 1\n",
    "\n",
    "# 네거: 배경형\n",
    "for _ in tqdm(range(neg_bg_n), desc=\"neg_bg\"):\n",
    "    bg_src = weighted_choice(neg_bg_items, neg_bg_w)\n",
    "    y = sample_background(bg_src)\n",
    "    y = apply_audio_aug(y)\n",
    "    write_feature(i, y, 0)\n",
    "    i += 1\n",
    "\n",
    "# 네거: 이벤트형(+50% 확률로 약한 배경 섞기)\n",
    "for _ in tqdm(range(neg_event_n), desc=\"neg_event\"):\n",
    "    evt_src = weighted_choice(neg_evt_items, neg_evt_w)\n",
    "    y = sample_event(evt_src)\n",
    "\n",
    "    if np.random.rand() < 0.50:\n",
    "        bg_src = weighted_choice(neg_bg_items, neg_bg_w)\n",
    "        bg = sample_background(bg_src)\n",
    "        snr = float(np.random.uniform(5.0, 25.0))\n",
    "        y = mix_at_snr(y, bg, snr)\n",
    "\n",
    "    y = apply_audio_aug(y)\n",
    "    write_feature(i, y, 0)\n",
    "    i += 1\n",
    "\n",
    "# flush\n",
    "X_mm.flush()\n",
    "y_mm.flush()\n",
    "\n",
    "# meta 저장\n",
    "meta = {\n",
    "    \"version\": \"v4\",\n",
    "    \"sr\": SR,\n",
    "    \"clip_seconds\": CLIP_SEC,\n",
    "    \"frames\": FRAMES,\n",
    "    \"mels\": N_MELS,\n",
    "    \"n_total\": int(N_TOTAL),\n",
    "    \"pos_total\": int(pos_total),\n",
    "    \"neg_total\": int(neg_total),\n",
    "    \"features_path\": str(X_PATH),\n",
    "    \"labels_path\": str(Y_PATH),\n",
    "}\n",
    "META_PATH.write_text(json.dumps(meta, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"written samples:\", i, \"expected:\", N_TOTAL)\n",
    "print(\"pos:\", int((y_mm[:] == 1).sum()), \"neg:\", int((y_mm[:] == 0).sum()))\n",
    "print(\"count_tf(frames):\", count_tf, \"expected:\", int(N_TOTAL * FRAMES))\n",
    "print(\"saved meta:\", META_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8b57781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mu shape: (64,) sd shape: (64,)\n",
      "saved: /content/work/out/v4/v4_norm_stats.npz\n"
     ]
    }
   ],
   "source": [
    "# mu/sd 계산(멜 bin별)\n",
    "mu = (sum_m / max(1, count_tf)).astype(np.float32)\n",
    "var = (sumsq_m / max(1, count_tf) - (mu.astype(np.float64) ** 2))\n",
    "var = np.maximum(var, 1e-8).astype(np.float32)\n",
    "sd = np.sqrt(var).astype(np.float32)\n",
    "\n",
    "stats_path = OUT_DIR / \"v4_norm_stats.npz\"\n",
    "np.savez(stats_path, mu=mu, sd=sd)\n",
    "\n",
    "print(\"mu shape:\", mu.shape, \"sd shape:\", sd.shape)\n",
    "print(\"saved:\", stats_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "746e1718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train n= 29399 pos= 8400 neg= 20999\n",
      "val   n= 6300 pos= 1800 neg= 4500\n",
      "test  n= 6301 pos= 1800 neg= 4501\n"
     ]
    }
   ],
   "source": [
    "!pip -q install scikit-learn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# labels 로드(작음)\n",
    "y_all = np.array(y_mm[:], dtype=np.int64)\n",
    "\n",
    "idx = np.arange(len(y_all))\n",
    "idx_train, idx_tmp, y_train, y_tmp = train_test_split(\n",
    "    idx, y_all, test_size=(1.0 - cfg[\"splits\"][\"train\"]), random_state=SEED, stratify=y_all\n",
    ")\n",
    "val_ratio = cfg[\"splits\"][\"val\"] / (cfg[\"splits\"][\"val\"] + cfg[\"splits\"][\"test\"])\n",
    "idx_val, idx_test, y_val, y_test = train_test_split(\n",
    "    idx_tmp, y_tmp, test_size=(1.0 - val_ratio), random_state=SEED, stratify=y_tmp\n",
    ")\n",
    "\n",
    "def counts(name, idxs):\n",
    "    yy = y_all[idxs]\n",
    "    print(name, \"n=\", len(idxs), \"pos=\", int(yy.sum()), \"neg=\", int((yy==0).sum()))\n",
    "\n",
    "counts(\"train\", idx_train)\n",
    "counts(\"val  \", idx_val)\n",
    "counts(\"test \", idx_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22fbc62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch X: (64, 198, 64, 1) batch y: (64,) pos_in_batch: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">198</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">49</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m1\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m198\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m99\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m4,640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m49\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,521</span> (107.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m27,521\u001b[0m (107.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">27,521</span> (107.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m27,521\u001b[0m (107.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# memmap 재오픈(안전)\n",
    "meta = json.loads((OUT_DIR / \"v4_meta.json\").read_text(encoding=\"utf-8\"))\n",
    "FRAMES = int(meta[\"frames\"])\n",
    "N_MELS = int(meta[\"mels\"])\n",
    "N_TOTAL = int(meta[\"n_total\"])\n",
    "\n",
    "X_mm = np.memmap(str(OUT_DIR / \"v4_features_f32.dat\"), dtype=\"float32\", mode=\"r\", shape=(N_TOTAL, FRAMES, N_MELS))\n",
    "y_all = np.array(np.memmap(str(OUT_DIR / \"v4_labels_i8.dat\"), dtype=\"int8\", mode=\"r\", shape=(N_TOTAL,)), dtype=np.int64)\n",
    "\n",
    "st = np.load(str(OUT_DIR / \"v4_norm_stats.npz\"))\n",
    "mu = st[\"mu\"].astype(np.float32)\n",
    "sd = st[\"sd\"].astype(np.float32)\n",
    "\n",
    "BATCH = int(cfg[\"training\"][\"batch_size\"])\n",
    "\n",
    "# on-the-fly specaugment(배치 단위)\n",
    "sa = cfg[\"augment\"][\"specaugment\"]\n",
    "SA_PROB = float(sa[\"apply_prob\"])\n",
    "SA_TM = int(sa[\"time_masks\"])\n",
    "SA_TMAX = int(sa[\"time_mask_max\"])\n",
    "SA_FM = int(sa[\"freq_masks\"])\n",
    "SA_FMAX = int(sa[\"freq_mask_max\"])\n",
    "\n",
    "def specaugment_np(f):\n",
    "    g = f.copy()\n",
    "    T, F = g.shape\n",
    "    for _ in range(SA_TM):\n",
    "        w = np.random.randint(0, SA_TMAX+1)\n",
    "        if w > 0 and T - w > 0:\n",
    "            t0 = np.random.randint(0, T - w)\n",
    "            g[t0:t0+w, :] = 0.0\n",
    "    for _ in range(SA_FM):\n",
    "        w = np.random.randint(0, SA_FMAX+1)\n",
    "        if w > 0 and F - w > 0:\n",
    "            f0 = np.random.randint(0, F - w)\n",
    "            g[:, f0:f0+w] = 0.0\n",
    "    return g\n",
    "\n",
    "def batch_generator(idxs, shuffle=True):\n",
    "    idxs = np.array(idxs, dtype=np.int64)\n",
    "    n = len(idxs)\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        for s in range(0, n, BATCH):\n",
    "            b = idxs[s:s+BATCH]\n",
    "            Xb = np.array(X_mm[b, :, :], dtype=np.float32)  # (B, frames, 64)\n",
    "\n",
    "            # 정규화\n",
    "            Xb = (Xb - mu[None, None, :]) / (sd[None, None, :] + 1e-6)\n",
    "\n",
    "            # specaugment(확률적)\n",
    "            if np.random.rand() < SA_PROB:\n",
    "                for i in range(Xb.shape[0]):\n",
    "                    Xb[i] = specaugment_np(Xb[i])\n",
    "\n",
    "            # 채널 추가\n",
    "            Xb = Xb[..., None]  # (B, frames, 64, 1)\n",
    "            yb = y_all[b].astype(np.float32)\n",
    "            yield Xb, yb\n",
    "\n",
    "# shape sanity check\n",
    "Xb0, yb0 = next(batch_generator(idx_train, shuffle=False))\n",
    "print(\"batch X:\", Xb0.shape, \"batch y:\", yb0.shape, \"pos_in_batch:\", int(yb0.sum()))\n",
    "\n",
    "def build_model(frames, mels):\n",
    "    inp = tf.keras.Input(shape=(frames, mels, 1))\n",
    "    x = tf.keras.layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(inp)\n",
    "    x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    x = tf.keras.layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPool2D((2,2))(x)\n",
    "    x = tf.keras.layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    out = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return tf.keras.Model(inp, out)\n",
    "\n",
    "model = build_model(FRAMES, N_MELS)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "295eeccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 695ms/step - auc: 0.7178 - loss: 0.5225 - prec: 0.6145 - rec: 0.2350 - val_auc: 0.9053 - val_loss: 0.3523 - val_prec: 0.7504 - val_rec: 0.7017 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 696ms/step - auc: 0.8975 - loss: 0.3572 - prec: 0.7658 - rec: 0.6737 - val_auc: 0.9242 - val_loss: 0.3173 - val_prec: 0.8064 - val_rec: 0.6856 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 703ms/step - auc: 0.9197 - loss: 0.3202 - prec: 0.7942 - rec: 0.7227 - val_auc: 0.9334 - val_loss: 0.3069 - val_prec: 0.8380 - val_rec: 0.6683 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 701ms/step - auc: 0.9308 - loss: 0.2979 - prec: 0.8140 - rec: 0.7516 - val_auc: 0.9417 - val_loss: 0.2886 - val_prec: 0.7626 - val_rec: 0.8160 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 699ms/step - auc: 0.9418 - loss: 0.2742 - prec: 0.8180 - rec: 0.7686 - val_auc: 0.9491 - val_loss: 0.2683 - val_prec: 0.8851 - val_rec: 0.7070 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 688ms/step - auc: 0.9433 - loss: 0.2722 - prec: 0.8261 - rec: 0.7803 - val_auc: 0.9534 - val_loss: 0.2465 - val_prec: 0.8504 - val_rec: 0.7839 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 693ms/step - auc: 0.9502 - loss: 0.2522 - prec: 0.8437 - rec: 0.7973 - val_auc: 0.9605 - val_loss: 0.2342 - val_prec: 0.8293 - val_rec: 0.8334 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9537 - loss: 0.2464 - prec: 0.8405 - rec: 0.8094 - val_auc: 0.9632 - val_loss: 0.2271 - val_prec: 0.8867 - val_rec: 0.7667 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 686ms/step - auc: 0.9578 - loss: 0.2346 - prec: 0.8541 - rec: 0.8079 - val_auc: 0.9600 - val_loss: 0.2433 - val_prec: 0.7775 - val_rec: 0.8865 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 695ms/step - auc: 0.9618 - loss: 0.2234 - prec: 0.8541 - rec: 0.8281 - val_auc: 0.9675 - val_loss: 0.2321 - val_prec: 0.9258 - val_rec: 0.7354 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9628 - loss: 0.2207 - prec: 0.8618 - rec: 0.8374 - val_auc: 0.9622 - val_loss: 0.2604 - val_prec: 0.7436 - val_rec: 0.9141 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9636 - loss: 0.2184 - prec: 0.8601 - rec: 0.8406 - val_auc: 0.9688 - val_loss: 0.2048 - val_prec: 0.8755 - val_rec: 0.8316 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9666 - loss: 0.2095 - prec: 0.8641 - rec: 0.8457 - val_auc: 0.9710 - val_loss: 0.1963 - val_prec: 0.8577 - val_rec: 0.8691 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9688 - loss: 0.2011 - prec: 0.8678 - rec: 0.8543 - val_auc: 0.9693 - val_loss: 0.2022 - val_prec: 0.8453 - val_rec: 0.8751 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 695ms/step - auc: 0.9710 - loss: 0.1949 - prec: 0.8771 - rec: 0.8647 - val_auc: 0.9734 - val_loss: 0.1872 - val_prec: 0.8795 - val_rec: 0.8571 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 698ms/step - auc: 0.9718 - loss: 0.1899 - prec: 0.8756 - rec: 0.8601 - val_auc: 0.9738 - val_loss: 0.1999 - val_prec: 0.8176 - val_rec: 0.9258 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 693ms/step - auc: 0.9717 - loss: 0.1918 - prec: 0.8709 - rec: 0.8616 - val_auc: 0.9754 - val_loss: 0.1786 - val_prec: 0.8913 - val_rec: 0.8620 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m317s\u001b[0m 690ms/step - auc: 0.9741 - loss: 0.1786 - prec: 0.8907 - rec: 0.8774 - val_auc: 0.9716 - val_loss: 0.1982 - val_prec: 0.8460 - val_rec: 0.8911 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 697ms/step - auc: 0.9758 - loss: 0.1756 - prec: 0.8918 - rec: 0.8787 - val_auc: 0.9786 - val_loss: 0.1721 - val_prec: 0.9114 - val_rec: 0.8395 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9779 - loss: 0.1671 - prec: 0.8983 - rec: 0.8816 - val_auc: 0.9787 - val_loss: 0.1684 - val_prec: 0.8670 - val_rec: 0.9071 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 694ms/step - auc: 0.9795 - loss: 0.1620 - prec: 0.8950 - rec: 0.8906 - val_auc: 0.9753 - val_loss: 0.1859 - val_prec: 0.9298 - val_rec: 0.8222 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9808 - loss: 0.1536 - prec: 0.9077 - rec: 0.8944 - val_auc: 0.9824 - val_loss: 0.1513 - val_prec: 0.9050 - val_rec: 0.8935 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9818 - loss: 0.1492 - prec: 0.9106 - rec: 0.9068 - val_auc: 0.9791 - val_loss: 0.1639 - val_prec: 0.9121 - val_rec: 0.8680 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 701ms/step - auc: 0.9825 - loss: 0.1495 - prec: 0.9106 - rec: 0.9047 - val_auc: 0.9830 - val_loss: 0.1478 - val_prec: 0.9163 - val_rec: 0.8904 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m315s\u001b[0m 686ms/step - auc: 0.9839 - loss: 0.1440 - prec: 0.9067 - rec: 0.9027 - val_auc: 0.9829 - val_loss: 0.1539 - val_prec: 0.9351 - val_rec: 0.8552 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 683ms/step - auc: 0.9830 - loss: 0.1465 - prec: 0.9062 - rec: 0.9020 - val_auc: 0.9834 - val_loss: 0.1450 - val_prec: 0.9033 - val_rec: 0.9003 - learning_rate: 5.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9842 - loss: 0.1390 - prec: 0.9116 - rec: 0.9126 - val_auc: 0.9837 - val_loss: 0.1433 - val_prec: 0.8987 - val_rec: 0.9091 - learning_rate: 5.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m319s\u001b[0m 693ms/step - auc: 0.9835 - loss: 0.1431 - prec: 0.9089 - rec: 0.9038 - val_auc: 0.9845 - val_loss: 0.1400 - val_prec: 0.9004 - val_rec: 0.9139 - learning_rate: 5.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 701ms/step - auc: 0.9837 - loss: 0.1428 - prec: 0.9147 - rec: 0.9042 - val_auc: 0.9845 - val_loss: 0.1387 - val_prec: 0.9043 - val_rec: 0.9159 - learning_rate: 5.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9872 - loss: 0.1277 - prec: 0.9188 - rec: 0.9142 - val_auc: 0.9828 - val_loss: 0.1480 - val_prec: 0.9258 - val_rec: 0.8776 - learning_rate: 5.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9875 - loss: 0.1260 - prec: 0.9246 - rec: 0.9178 - val_auc: 0.9853 - val_loss: 0.1356 - val_prec: 0.9099 - val_rec: 0.9114 - learning_rate: 2.5000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m383s\u001b[0m 832ms/step - auc: 0.9873 - loss: 0.1231 - prec: 0.9276 - rec: 0.9197 - val_auc: 0.9864 - val_loss: 0.1324 - val_prec: 0.9211 - val_rec: 0.8930 - learning_rate: 2.5000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 699ms/step - auc: 0.9864 - loss: 0.1300 - prec: 0.9217 - rec: 0.9113 - val_auc: 0.9862 - val_loss: 0.1373 - val_prec: 0.8883 - val_rec: 0.9429 - learning_rate: 2.5000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 700ms/step - auc: 0.9880 - loss: 0.1193 - prec: 0.9282 - rec: 0.9241 - val_auc: 0.9853 - val_loss: 0.1354 - val_prec: 0.9187 - val_rec: 0.8962 - learning_rate: 2.5000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m460/460\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 699ms/step - auc: 0.9887 - loss: 0.1160 - prec: 0.9300 - rec: 0.9225 - val_auc: 0.9861 - val_loss: 0.1388 - val_prec: 0.8815 - val_rec: 0.9422 - learning_rate: 1.2500e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m193/460\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m2:52\u001b[0m 644ms/step - auc: 0.9887 - loss: 0.1176 - prec: 0.9322 - rec: 0.9225"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://8080-m-s-1604ul2u4jcof-a.us-east4-1.prod.colab.dev/'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "lr = float(cfg[\"training\"][\"lr\"])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\n",
    "        tf.keras.metrics.AUC(name=\"auc\"),\n",
    "        tf.keras.metrics.Precision(name=\"prec\"),\n",
    "        tf.keras.metrics.Recall(name=\"rec\"),\n",
    "    ],\n",
    ")\n",
    "\n",
    "ckpt_path = OUT_DIR / \"v4_model.keras\"\n",
    "\n",
    "steps_per_epoch = math.ceil(len(idx_train) / BATCH)\n",
    "val_steps = math.ceil(len(idx_val) / BATCH)\n",
    "\n",
    "train_gen = batch_generator(idx_train, shuffle=True)\n",
    "val_gen   = batch_generator(idx_val, shuffle=False)\n",
    "\n",
    "cbs = [\n",
    "    tf.keras.callbacks.ModelCheckpoint(\n",
    "        str(ckpt_path),\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        patience=6,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_auc\",\n",
    "        mode=\"max\",\n",
    "        patience=2,\n",
    "        factor=0.5,\n",
    "    ),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=100,\n",
    "    callbacks=cbs,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "print(\"saved best:\", ckpt_path)\n",
    "\"|}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14361c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v4\n"
     ]
    }
   ],
   "source": [
    "!ls /content/work/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5f2861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion @0.5:\n",
      " [[4387  114]\n",
      " [ 143 1657]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9684    0.9747    0.9715      4501\n",
      "           1     0.9356    0.9206    0.9280      1800\n",
      "\n",
      "    accuracy                         0.9592      6301\n",
      "   macro avg     0.9520    0.9476    0.9498      6301\n",
      "weighted avg     0.9591    0.9592    0.9591      6301\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "model = tf.keras.models.load_model(str(ckpt_path))\n",
    "\n",
    "def predict_on_idxs(idxs):\n",
    "    probs = []\n",
    "    ys = []\n",
    "    for s in range(0, len(idxs), BATCH):\n",
    "        b = np.array(idxs[s:s+BATCH], dtype=np.int64)\n",
    "        Xb = np.array(X_mm[b, :, :], dtype=np.float32)\n",
    "        Xb = (Xb - mu[None, None, :]) / (sd[None, None, :] + 1e-6)\n",
    "        Xb = Xb[..., None]\n",
    "        pb = model.predict(Xb, verbose=0).reshape(-1)\n",
    "        probs.append(pb)\n",
    "        ys.append(y_all[b])\n",
    "    return np.concatenate(probs), np.concatenate(ys)\n",
    "\n",
    "p_test, y_test = predict_on_idxs(idx_test)\n",
    "\n",
    "thr = 0.5\n",
    "yhat = (p_test >= thr).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, yhat)\n",
    "print(\"confusion @0.5:\\n\", cm)\n",
    "print(classification_report(y_test, yhat, digits=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3bdc7a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_on_idxs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4159621967.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mp_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_on_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_on_idxs' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "p_val, y_val2 = predict_on_idxs(idx_val)\n",
    "\n",
    "prec, rec, th = precision_recall_curve(y_val2, p_val)\n",
    "\n",
    "target_prec = float(cfg[\"thresholding\"][\"target_precision\"])\n",
    "fallback = float(cfg[\"thresholding\"][\"fallback_threshold\"])\n",
    "\n",
    "cands = [(t, p, r) for t, p, r in zip(th, prec[:-1], rec[:-1]) if p >= target_prec]\n",
    "if len(cands) == 0:\n",
    "    best_t = fallback\n",
    "    best_p = float(prec[0])\n",
    "    best_r = float(rec[0])\n",
    "else:\n",
    "    best_t, best_p, best_r = sorted(cands, key=lambda x: x[2], reverse=True)[0]\n",
    "\n",
    "thr_path = OUT_DIR / \"v4_threshold.txt\"\n",
    "thr_path.write_text(f\"{best_t}\\n\", encoding=\"utf-8\")\n",
    "\n",
    "print(\"selected threshold:\", best_t, \"precision:\", best_p, \"recall:\", best_r)\n",
    "print(\"saved:\", thr_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7909c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cp: cannot stat '/content/work/out': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!cp -r /content/work/out/v4 /content/drive/MyDrive/sneeze_models_v4/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b924d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sneeze-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
