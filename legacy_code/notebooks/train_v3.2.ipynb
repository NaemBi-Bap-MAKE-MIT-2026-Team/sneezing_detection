{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "565286ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install numpy pandas soundfile librosa tensorflow tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80536b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc4b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DRIVE_SNEEZE exists: True /content/drive/MyDrive/sneeze_models\n",
      "ZIP exists: True /content/drive/MyDrive/raw_data.zip\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DRIVE_ROOT = Path(\"/content/drive/MyDrive\")\n",
    "DRIVE_SNEEZE = DRIVE_ROOT / \"sneeze_models\"          # 드라이브에 있는 sneeze_model 폴더\n",
    "ZIP_PATH = DRIVE_ROOT / \"raw_data.zip\"      # 효민님이 새로 만든 zip 파일명으로 맞추기\n",
    "\n",
    "print(\"DRIVE_SNEEZE exists:\", DRIVE_SNEEZE.exists(), DRIVE_SNEEZE)\n",
    "print(\"ZIP exists:\", ZIP_PATH.exists(), ZIP_PATH)\n",
    "\n",
    "# 필수 체크\n",
    "assert DRIVE_SNEEZE.exists(), \"드라이브의 sneeze_model 폴더 경로가 틀렸습니다. DRIVE_SNEEZE를 수정하십시오.\"\n",
    "assert ZIP_PATH.exists(), \"zip 경로가 틀렸습니다. ZIP_PATH를 수정하십시오.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f216314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WORK exists: True\n",
      "WORK contents:\n",
      " - /content/work/MS-SNSD-NOISE (dir)\n",
      " - /content/work/esc-50 (dir)\n",
      " - /content/work/recordings (dir)\n",
      " - /content/work/sneeze (dir)\n"
     ]
    }
   ],
   "source": [
    "import shutil, os\n",
    "\n",
    "WORK = Path(\"/content/work\")\n",
    "\n",
    "# zip 풀기\n",
    "!unzip -q \"{ZIP_PATH}\" -d \"{WORK}\"\n",
    "\n",
    "print(\"WORK exists:\", WORK.exists())\n",
    "print(\"WORK contents:\")\n",
    "for p in sorted(WORK.iterdir()):\n",
    "    print(\" -\", p, \"(dir)\" if p.is_dir() else \"(file)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1b7c76ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STATS: True /content/drive/MyDrive/sneeze_models/norm_stats.npz\n",
      "TFLITE: True /content/drive/MyDrive/sneeze_models/v3_1_model.tflite\n",
      "KERAS: True /content/drive/MyDrive/sneeze_models/v3_1_model.keras\n",
      "THR: True /content/drive/MyDrive/sneeze_models/v3_1_threshold.txt\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DRIVE_DIR = Path(\"/content/drive/MyDrive/sneeze_models\")\n",
    "assert DRIVE_DIR.exists(), f\"not found: {DRIVE_DIR}\"\n",
    "\n",
    "STATS_SRC = DRIVE_DIR / \"norm_stats.npz\"\n",
    "TFLITE_SRC = DRIVE_DIR / \"v3_1_model.tflite\"\n",
    "KERAS_SRC = DRIVE_DIR / \"v3_1_model.keras\"\n",
    "THR_SRC = DRIVE_DIR / \"v3_1_threshold.txt\"\n",
    "\n",
    "print(\"STATS:\", STATS_SRC.exists(), STATS_SRC)\n",
    "print(\"TFLITE:\", TFLITE_SRC.exists(), TFLITE_SRC)\n",
    "print(\"KERAS:\", KERAS_SRC.exists(), KERAS_SRC)\n",
    "print(\"THR:\", THR_SRC.exists(), THR_SRC)\n",
    "\n",
    "assert STATS_SRC.exists(), \"norm_stats.npz 없음\"\n",
    "assert TFLITE_SRC.exists(), \"v3_1_model.tflite 없음\"\n",
    "assert KERAS_SRC.exists(), \"v3_1_model.keras 없음\"\n",
    "assert THR_SRC.exists(), \"v3_1_threshold.txt 없음\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10c49463",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied to: /content/work/out\n",
      "total 332K\n",
      "drwxr-xr-x 3 root root 4.0K Feb 15 16:01 .\n",
      "drwxr-xr-x 7 root root 4.0K Feb 15 15:59 ..\n",
      "drwxr-xr-x 2 root root 4.0K Feb 15 15:59 hard_negs_v3\n",
      "-rw------- 1 root root  912 Feb 15 06:32 norm_stats.npz\n",
      "-rw------- 1 root root  17K Feb 15 06:32 sneeze_ds_cnn_dynamic.tflite\n",
      "-rw------- 1 root root 132K Feb 15 06:32 sneeze_ds_cnn.keras\n",
      "-rw------- 1 root root   19 Feb 15 06:32 threshold.txt\n",
      "-rw------- 1 root root 131K Feb 15 06:32 v3_1_model.keras\n",
      "-rw------- 1 root root  21K Feb 15 06:32 v3_1_model.tflite\n",
      "-rw------- 1 root root   18 Feb 15 06:32 v3_1_threshold.txt\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "WORK = Path(\"/content/work\")\n",
    "OUT_DIR = WORK / \"out\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "shutil.copy2(STATS_SRC, OUT_DIR / \"norm_stats.npz\")\n",
    "shutil.copy2(TFLITE_SRC, OUT_DIR / \"v3_1_model.tflite\")\n",
    "shutil.copy2(KERAS_SRC, OUT_DIR / \"v3_1_model.keras\")\n",
    "shutil.copy2(THR_SRC, OUT_DIR / \"v3_1_threshold.txt\")\n",
    "\n",
    "print(\"Copied to:\", OUT_DIR)\n",
    "!ls -lah /content/work/out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bab59501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3_STATS: True /content/work/out/norm_stats.npz\n",
      "V3_KERAS: True /content/work/out/v3_1_model.keras\n",
      "V3_TFLITE: True /content/work/out/v3_1_model.tflite\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "WORK = Path(\"/content/work\")\n",
    "OUT_DIR = WORK / \"out\"\n",
    "\n",
    "V3_STATS = OUT_DIR / \"norm_stats.npz\"\n",
    "V3_KERAS = OUT_DIR / \"v3_1_model.keras\"   # 이어학습 시작점\n",
    "V3_TFLITE = OUT_DIR / \"v3_1_model.tflite\"\n",
    "\n",
    "print(\"V3_STATS:\", V3_STATS.exists(), V3_STATS)\n",
    "print(\"V3_KERAS:\", V3_KERAS.exists(), V3_KERAS)\n",
    "print(\"V3_TFLITE:\", V3_TFLITE.exists(), V3_TFLITE)\n",
    "\n",
    "assert V3_STATS.exists()\n",
    "assert V3_KERAS.exists()\n",
    "assert V3_TFLITE.exists()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "229a07ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESC50_DIR: True /content/work/esc-50\n",
      "MS_SNSD_DIR: True /content/work/MS-SNSD-NOISE\n",
      "SNEEZE_DIR: True /content/work/sneeze\n",
      "REC_DIR: True /content/work/recordings\n",
      "OUT_DIR: True /content/work/out\n",
      "V3_KERAS: True /content/work/out/sneeze_ds_cnn.keras\n",
      "V3_TFLITE: True /content/work/out/sneeze_ds_cnn_dynamic.tflite\n",
      "V3_STATS: True /content/work/out/norm_stats.npz\n",
      "YAHO_WAV: True /content/work/recordings/yaho.wav\n"
     ]
    }
   ],
   "source": [
    "ESC50_DIR  = WORK / \"esc-50\"\n",
    "MS_SNSD_DIR = WORK / \"MS-SNSD-NOISE\"\n",
    "SNEEZE_DIR = WORK / \"sneeze\"\n",
    "REC_DIR    = WORK / \"recordings\"\n",
    "OUT_DIR    = WORK / \"out\"\n",
    "\n",
    "# v3 기준(이어학습 시작점)\n",
    "V3_KERAS  = OUT_DIR / \"sneeze_ds_cnn.keras\"\n",
    "V3_TFLITE = OUT_DIR / \"sneeze_ds_cnn_dynamic.tflite\"\n",
    "V3_STATS  = OUT_DIR / \"norm_stats.npz\"\n",
    "\n",
    "# v3.2에서 추가할 새 네거티브 파일\n",
    "YAHO_WAV = REC_DIR / \"yaho.wav\"\n",
    "\n",
    "print(\"ESC50_DIR:\", ESC50_DIR.exists(), ESC50_DIR)\n",
    "print(\"MS_SNSD_DIR:\", MS_SNSD_DIR.exists(), MS_SNSD_DIR)\n",
    "print(\"SNEEZE_DIR:\", SNEEZE_DIR.exists(), SNEEZE_DIR)\n",
    "print(\"REC_DIR:\", REC_DIR.exists(), REC_DIR)\n",
    "print(\"OUT_DIR:\", OUT_DIR.exists(), OUT_DIR)\n",
    "\n",
    "print(\"V3_KERAS:\", V3_KERAS.exists(), V3_KERAS)\n",
    "print(\"V3_TFLITE:\", V3_TFLITE.exists(), V3_TFLITE)\n",
    "print(\"V3_STATS:\", V3_STATS.exists(), V3_STATS)\n",
    "print(\"YAHO_WAV:\", YAHO_WAV.exists(), YAHO_WAV)\n",
    "\n",
    "assert V3_STATS.exists(), \"norm_stats.npz가 없습니다. 드라이브 out 복사가 제대로 됐는지 확인하십시오.\"\n",
    "assert YAHO_WAV.exists(), \"recordings/yaho.wav가 zip에 포함되지 않았습니다. zip 구성 확인 필요.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "262aef0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats loaded: /content/work/out/norm_stats.npz mu: (64,) sd: (64,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "OUT_DIR = WORK / \"out\"\n",
    "STATS_PATH = OUT_DIR / \"norm_stats.npz\"\n",
    "assert STATS_PATH.exists(), f\"not found: {STATS_PATH}\"\n",
    "\n",
    "st = np.load(str(STATS_PATH), allow_pickle=True)\n",
    "mu = st[\"mu\"].astype(np.float32).reshape(-1)\n",
    "sdv = st[\"sd\"].astype(np.float32).reshape(-1)\n",
    "\n",
    "print(\"stats loaded:\", STATS_PATH, \"mu:\", mu.shape, \"sd:\", sdv.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2229a297",
   "metadata": {},
   "source": [
    "## 3) 노트북 셀: 네거티브 샘플링을 “새 파일에 편향”시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cadf0a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "POS_N: 968 NEG_TARGET: 3872\n",
      "NEG_FROM_YAHO: 2129 NEG_FROM_OTHERS: 1743\n",
      "neg_yaho: 2129\n",
      "neg_other: 1743\n"
     ]
    }
   ],
   "source": [
    "import random, librosa\n",
    "import numpy as np\n",
    "\n",
    "SR = 16000\n",
    "CLIP_SECONDS = 2.0\n",
    "CLIP_SAMPLES = int(SR * CLIP_SECONDS)\n",
    "\n",
    "def rms(x, eps=1e-8):\n",
    "    x = np.asarray(x, np.float32)\n",
    "    return float(np.sqrt(np.mean(x*x) + eps))\n",
    "\n",
    "def load_wav_mono_16k(path):\n",
    "    y, _ = librosa.load(str(path), sr=SR, mono=True)\n",
    "    return y.astype(np.float32)\n",
    "\n",
    "def fix_2s(y):\n",
    "    if len(y) >= CLIP_SAMPLES:\n",
    "        return y[:CLIP_SAMPLES].astype(np.float32)\n",
    "    return np.pad(y.astype(np.float32), (0, CLIP_SAMPLES - len(y)))\n",
    "\n",
    "def clip_from_long(y, start_sec):\n",
    "    s = int(start_sec * SR)\n",
    "    e = s + CLIP_SAMPLES\n",
    "    return fix_2s(y[s:e])\n",
    "\n",
    "def sample_neg_from_long(path, n_samples, min_rms=0.003):\n",
    "    y = load_wav_mono_16k(path)\n",
    "    if len(y) < CLIP_SAMPLES:\n",
    "        return []\n",
    "    dur = len(y) / SR\n",
    "    out = []\n",
    "    tries = 0\n",
    "    max_tries = n_samples * 40\n",
    "\n",
    "    while len(out) < n_samples and tries < max_tries:\n",
    "        tries += 1\n",
    "        start = random.uniform(0, max(0.0, dur - CLIP_SECONDS))\n",
    "        seg = clip_from_long(y, start)\n",
    "        if rms(seg) < min_rms:\n",
    "            continue\n",
    "        out.append(seg)\n",
    "    return out\n",
    "\n",
    "# pos 개수 기반으로 네거티브 목표 결정\n",
    "SNEEZE_DIR = WORK / \"sneeze\"\n",
    "pos_files = sorted([p for p in SNEEZE_DIR.rglob(\"*.wav\")])\n",
    "POS_N = len(pos_files)\n",
    "NEG_TARGET = POS_N * 4\n",
    "\n",
    "# 새 파일에서 얼마나 많이 뽑을지\n",
    "NEG_FROM_YAHO = int(NEG_TARGET * 0.55)  # 55%를 yaho에서\n",
    "NEG_FROM_OTHERS = NEG_TARGET - NEG_FROM_YAHO\n",
    "\n",
    "print(\"POS_N:\", POS_N, \"NEG_TARGET:\", NEG_TARGET)\n",
    "print(\"NEG_FROM_YAHO:\", NEG_FROM_YAHO, \"NEG_FROM_OTHERS:\", NEG_FROM_OTHERS)\n",
    "\n",
    "neg_yaho = sample_neg_from_long(YAHO_WAV, NEG_FROM_YAHO, min_rms=0.003)\n",
    "print(\"neg_yaho:\", len(neg_yaho))\n",
    "\n",
    "ESC50_DIR = WORK / \"esc-50\"\n",
    "MS_SNSD_DIR = WORK / \"MS-SNSD-NOISE\"\n",
    "REC_FILES = sorted([p for p in (WORK/\"recordings\").rglob(\"*.wav\") if p.name != YAHO_WAV.name])\n",
    "esc_files = sorted([p for p in ESC50_DIR.rglob(\"*.wav\")])\n",
    "ms_files  = sorted([p for p in MS_SNSD_DIR.rglob(\"*.wav\")])\n",
    "\n",
    "def sample_neg_from_short(path):\n",
    "    y = load_wav_mono_16k(path)\n",
    "    return fix_2s(y)\n",
    "\n",
    "neg_other = []\n",
    "\n",
    "# recordings에서 일부\n",
    "if len(REC_FILES) > 0:\n",
    "    per_file = max(1, (NEG_FROM_OTHERS // 2) // len(REC_FILES))\n",
    "    for p in REC_FILES:\n",
    "        neg_other.extend(sample_neg_from_long(p, per_file, min_rms=0.003))\n",
    "\n",
    "# esc/ms에서 일부\n",
    "need = NEG_FROM_OTHERS - len(neg_other)\n",
    "need = max(0, need)\n",
    "\n",
    "take_esc = min(len(esc_files), need // 2)\n",
    "take_ms  = min(len(ms_files),  need - take_esc)\n",
    "\n",
    "for p in random.sample(esc_files, take_esc):\n",
    "    neg_other.append(sample_neg_from_short(p))\n",
    "for p in random.sample(ms_files, take_ms):\n",
    "    neg_other.append(sample_neg_from_short(p))\n",
    "\n",
    "# 부족하면 recordings에서 더 채움\n",
    "while len(neg_other) < NEG_FROM_OTHERS and len(REC_FILES) > 0:\n",
    "    p = random.choice(REC_FILES)\n",
    "    neg_other.extend(sample_neg_from_long(p, 30, min_rms=0.003))\n",
    "    neg_other = neg_other[:NEG_FROM_OTHERS]\n",
    "\n",
    "print(\"neg_other:\", len(neg_other))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06afd537",
   "metadata": {},
   "source": [
    "## 4) 노트북 셀: 포지티브 로드 (2초 고정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d321507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_audio: 968 neg_audio: 3872\n"
     ]
    }
   ],
   "source": [
    "pos_audio = []\n",
    "for p in pos_files:\n",
    "    y = load_wav_mono_16k(p)\n",
    "    pos_audio.append(fix_2s(y))\n",
    "\n",
    "neg_audio = neg_yaho + neg_other\n",
    "\n",
    "print(\"pos_audio:\", len(pos_audio), \"neg_audio:\", len(neg_audio))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344ba656",
   "metadata": {},
   "source": [
    "## 5) 노트북 셀: 특징(log-mel) 추출 + v3 stats로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12502d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: (4840, 201, 64, 1) y: (4840,) pos: 968 neg: 3872\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "\n",
    "N_MELS = 64\n",
    "N_FFT  = 400\n",
    "HOP    = 160\n",
    "TARGET_RMS = 0.1\n",
    "\n",
    "def normalize_rms(x, target=TARGET_RMS):\n",
    "    r = rms(x)\n",
    "    if r > 1e-6:\n",
    "        x = x * (target / (r + 1e-8))\n",
    "    return np.clip(x, -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def logmel(y):\n",
    "    S = librosa.feature.melspectrogram(\n",
    "        y=y, sr=SR, n_fft=N_FFT, hop_length=HOP, n_mels=N_MELS, power=2.0\n",
    "    )\n",
    "    return np.log(S + 1e-6).T.astype(np.float32)\n",
    "\n",
    "def feats_list(audio_list):\n",
    "    feats = []\n",
    "    for y in audio_list:\n",
    "        y = normalize_rms(fix_2s(y))\n",
    "        f = logmel(y)\n",
    "        f = (f - mu) / (sdv + 1e-6)\n",
    "        feats.append(f)\n",
    "    return np.array(feats, dtype=np.float32)\n",
    "\n",
    "X_pos = feats_list(pos_audio)\n",
    "X_neg = feats_list(neg_audio)\n",
    "\n",
    "X = np.concatenate([X_pos, X_neg], axis=0)[..., None]\n",
    "y = np.array([1]*len(X_pos) + [0]*len(X_neg), dtype=np.int64)\n",
    "\n",
    "print(\"X:\", X.shape, \"y:\", y.shape, \"pos:\", int(y.sum()), \"neg:\", int((y==0).sum()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae946ee",
   "metadata": {},
   "source": [
    "## 6) 노트북 셀: 분할 + v3에서 이어학습해서 v3.2 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ca96658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (3388, 201, 64, 1) pos_rate: 0.2001180637544274\n",
      "val: (726, 201, 64, 1) pos_rate: 0.19972451790633608\n",
      "test: (726, 201, 64, 1) pos_rate: 0.19972451790633608\n",
      "loaded: /content/work/out/sneeze_ds_cnn.keras\n",
      "class_weight: {0: 1.0, 1: 3.997050141597271}\n",
      "Epoch 1/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 959ms/step - auc: 0.9370 - loss: 0.5065 - precision: 0.6560 - recall: 0.8489 - val_auc: 0.9804 - val_loss: 0.2333 - val_precision: 0.6931 - val_recall: 0.9655 - learning_rate: 5.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 982ms/step - auc: 0.9824 - loss: 0.2400 - precision: 0.8619 - recall: 0.9582 - val_auc: 0.9848 - val_loss: 0.2534 - val_precision: 0.6847 - val_recall: 0.9586 - learning_rate: 5.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 957ms/step - auc: 0.9789 - loss: 0.2631 - precision: 0.8768 - recall: 0.9376 - val_auc: 0.9903 - val_loss: 0.1348 - val_precision: 0.8726 - val_recall: 0.9448 - learning_rate: 5.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 976ms/step - auc: 0.9905 - loss: 0.1918 - precision: 0.8766 - recall: 0.9601 - val_auc: 0.9955 - val_loss: 0.0995 - val_precision: 0.9267 - val_recall: 0.9586 - learning_rate: 5.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 1s/step - auc: 0.9916 - loss: 0.1755 - precision: 0.8799 - recall: 0.9536 - val_auc: 0.9959 - val_loss: 0.1002 - val_precision: 0.9038 - val_recall: 0.9724 - learning_rate: 5.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 951ms/step - auc: 0.9911 - loss: 0.1858 - precision: 0.8724 - recall: 0.9620 - val_auc: 0.9971 - val_loss: 0.0797 - val_precision: 0.9592 - val_recall: 0.9724 - learning_rate: 5.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 997ms/step - auc: 0.9944 - loss: 0.1603 - precision: 0.9150 - recall: 0.9556 - val_auc: 0.9972 - val_loss: 0.0712 - val_precision: 0.9774 - val_recall: 0.8966 - learning_rate: 5.0000e-04\n",
      "Epoch 8/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 995ms/step - auc: 0.9925 - loss: 0.1738 - precision: 0.8854 - recall: 0.9609 - val_auc: 0.9975 - val_loss: 0.0666 - val_precision: 0.9714 - val_recall: 0.9379 - learning_rate: 5.0000e-04\n",
      "Epoch 9/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 966ms/step - auc: 0.9953 - loss: 0.1369 - precision: 0.9117 - recall: 0.9753 - val_auc: 0.9972 - val_loss: 0.0637 - val_precision: 0.9720 - val_recall: 0.9586 - learning_rate: 5.0000e-04\n",
      "Epoch 10/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 995ms/step - auc: 0.9944 - loss: 0.1501 - precision: 0.8953 - recall: 0.9634 - val_auc: 0.9974 - val_loss: 0.0695 - val_precision: 0.9658 - val_recall: 0.9724 - learning_rate: 5.0000e-04\n",
      "Epoch 11/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 976ms/step - auc: 0.9934 - loss: 0.1524 - precision: 0.9036 - recall: 0.9694 - val_auc: 0.9977 - val_loss: 0.0698 - val_precision: 0.9521 - val_recall: 0.9586 - learning_rate: 2.5000e-04\n",
      "Epoch 12/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 969ms/step - auc: 0.9935 - loss: 0.1504 - precision: 0.9112 - recall: 0.9736 - val_auc: 0.9978 - val_loss: 0.0580 - val_precision: 0.9716 - val_recall: 0.9448 - learning_rate: 2.5000e-04\n",
      "Epoch 13/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 975ms/step - auc: 0.9940 - loss: 0.1487 - precision: 0.8953 - recall: 0.9697 - val_auc: 0.9976 - val_loss: 0.0598 - val_precision: 0.9653 - val_recall: 0.9586 - learning_rate: 2.5000e-04\n",
      "Epoch 14/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 985ms/step - auc: 0.9952 - loss: 0.1376 - precision: 0.9160 - recall: 0.9634 - val_auc: 0.9975 - val_loss: 0.0579 - val_precision: 0.9716 - val_recall: 0.9448 - learning_rate: 2.5000e-04\n",
      "Epoch 15/15\n",
      "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 935ms/step - auc: 0.9954 - loss: 0.1233 - precision: 0.9191 - recall: 0.9815 - val_auc: 0.9972 - val_loss: 0.0588 - val_precision: 0.9722 - val_recall: 0.9655 - learning_rate: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "SEED = 42\n",
    "idx = np.arange(len(y))\n",
    "idx_train, idx_tmp, y_train, y_tmp = train_test_split(idx, y, test_size=0.30, random_state=SEED, stratify=y)\n",
    "idx_val, idx_test, y_val, y_test = train_test_split(idx_tmp, y_tmp, test_size=0.50, random_state=SEED, stratify=y_tmp)\n",
    "\n",
    "X_train, X_val, X_test = X[idx_train], X[idx_val], X[idx_test]\n",
    "y_train, y_val, y_test = y[idx_train], y[idx_val], y[idx_test]\n",
    "\n",
    "print(\"train:\", X_train.shape, \"pos_rate:\", float(y_train.mean()))\n",
    "print(\"val:\", X_val.shape, \"pos_rate:\", float(y_val.mean()))\n",
    "print(\"test:\", X_test.shape, \"pos_rate:\", float(y_test.mean()))\n",
    "\n",
    "V3_KERAS = OUT_DIR / \"sneeze_ds_cnn.keras\"  # 효민님 out 목록 기준\n",
    "assert V3_KERAS.exists(), f\"not found: {V3_KERAS}\"\n",
    "\n",
    "model = tf.keras.models.load_model(str(V3_KERAS))\n",
    "print(\"loaded:\", V3_KERAS)\n",
    "\n",
    "pos = int((y_train==1).sum())\n",
    "neg = int((y_train==0).sum())\n",
    "class_weight = {0: 1.0, 1: neg / (pos + 1e-6)}\n",
    "print(\"class_weight:\", class_weight)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(5e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[tf.keras.metrics.AUC(name=\"auc\"), tf.keras.metrics.Precision(name=\"precision\"), tf.keras.metrics.Recall(name=\"recall\")],\n",
    ")\n",
    "\n",
    "cb = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_auc\", mode=\"max\", patience=4, restore_best_weights=True),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_auc\", mode=\"max\", factor=0.5, patience=2, min_lr=1e-5),\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=15,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weight,\n",
    "    callbacks=cb,\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc24680",
   "metadata": {},
   "source": [
    "## 7) 노트북 셀: threshold 재선정 + 저장(v3.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77fa99ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val auc: 0.9977802836963617\n",
      "test auc: 0.993673215027598\n",
      "chosen threshold: 0.3950975239276886\n",
      "confusion_matrix:\n",
      " [[571  10]\n",
      " [ 11 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.9828    0.9819       581\n",
      "           1     0.9306    0.9241    0.9273       145\n",
      "\n",
      "    accuracy                         0.9711       726\n",
      "   macro avg     0.9558    0.9535    0.9546       726\n",
      "weighted avg     0.9710    0.9711    0.9710       726\n",
      "\n",
      "Saved artifact at '/tmp/tmpuybbpmje'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 201, 64, 1), dtype=tf.float32, name='input_layer')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 1), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  138536561976400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561976592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561978320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561978128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561977744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561979472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561979664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561976976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561980432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561980624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561979280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561978704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561978512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561980240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561982352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561982928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561981776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561981392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561982736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561981200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561982160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561982544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561983120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536561981968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536558379664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  138536558380240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "saved: /content/work/out/v3_2_model.keras\n",
      "saved: /content/work/out/v3_2_model.tflite\n",
      "saved: /content/work/out/v3_2_threshold.txt\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score, confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "val_prob = model.predict(X_val, verbose=0).reshape(-1)\n",
    "test_prob = model.predict(X_test, verbose=0).reshape(-1)\n",
    "\n",
    "print(\"val auc:\", roc_auc_score(y_val, val_prob))\n",
    "print(\"test auc:\", roc_auc_score(y_test, test_prob))\n",
    "\n",
    "fpr, tpr, thr = roc_curve(y_val, val_prob)\n",
    "\n",
    "target_fpr = 0.01\n",
    "candidates = [(t, tp, fp) for t, tp, fp in zip(thr, tpr, fpr) if fp <= target_fpr]\n",
    "best_thr = 0.5 if len(candidates)==0 else sorted(candidates, key=lambda x: x[1], reverse=True)[0][0]\n",
    "\n",
    "print(\"chosen threshold:\", float(best_thr))\n",
    "\n",
    "test_pred = (test_prob >= best_thr).astype(int)\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "print(\"confusion_matrix:\\n\", cm)\n",
    "print(classification_report(y_test, test_pred, digits=4))\n",
    "\n",
    "SAVE_KERAS  = OUT_DIR / \"v3_2_model.keras\"\n",
    "SAVE_TFLITE = OUT_DIR / \"v3_2_model.tflite\"\n",
    "SAVE_THR    = OUT_DIR / \"v3_2_threshold.txt\"\n",
    "\n",
    "model.save(str(SAVE_KERAS))\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "SAVE_TFLITE.write_bytes(tflite_model)\n",
    "\n",
    "SAVE_THR.write_text(str(float(best_thr)))\n",
    "\n",
    "print(\"saved:\", SAVE_KERAS)\n",
    "print(\"saved:\", SAVE_TFLITE)\n",
    "print(\"saved:\", SAVE_THR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9224bc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hard_negs_v3\t\t      threshold.txt\t  v3_2_model.keras\n",
      "norm_stats.npz\t\t      v3_1_model.keras\t  v3_2_model.tflite\n",
      "sneeze_ds_cnn_dynamic.tflite  v3_1_model.tflite   v3_2_threshold.txt\n",
      "sneeze_ds_cnn.keras\t      v3_1_threshold.txt\n"
     ]
    }
   ],
   "source": [
    "!ls /content/work/out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44a26794",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r /content/work/out /content/drive/MyDrive/sneeze_models_v3.2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "19a23e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VAL pos count: 145 neg count: 581\n",
      "POS  mean/std/min/p10/median/p90/max: 0.9120925664901733 0.16790898144245148 0.14783266186714172 0.7078515291213989 0.9860939979553223 0.9974110722541809 0.9995041489601135\n",
      "NEG  mean/std/min/p10/median/p90/max: 0.029235580936074257 0.08051810413599014 3.2762800401542336e-05 0.0015809355536475778 0.009090131148695946 0.06179283931851387 0.9890066385269165\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "val_prob = model.predict(X_val, verbose=0).reshape(-1)\n",
    "\n",
    "pos = val_prob[y_val == 1]\n",
    "neg = val_prob[y_val == 0]\n",
    "\n",
    "print(\"VAL pos count:\", len(pos), \"neg count:\", len(neg))\n",
    "print(\"POS  mean/std/min/p10/median/p90/max:\",\n",
    "      float(pos.mean()), float(pos.std()), float(pos.min()),\n",
    "      float(np.percentile(pos,10)), float(np.median(pos)),\n",
    "      float(np.percentile(pos,90)), float(pos.max()))\n",
    "\n",
    "print(\"NEG  mean/std/min/p10/median/p90/max:\",\n",
    "      float(neg.mean()), float(neg.std()), float(neg.min()),\n",
    "      float(np.percentile(neg,10)), float(np.median(neg)),\n",
    "      float(np.percentile(neg,90)), float(neg.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51480568",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
