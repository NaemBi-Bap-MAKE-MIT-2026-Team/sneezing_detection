{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaeab8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# 1. 구글 드라이브 마운트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. 압축 파일 복사 (드라이브 -> VM 로컬)\n",
    "!cp /content/drive/MyDrive/final_dataset.zip /content/\n",
    "\n",
    "# 3. 압축 해제\n",
    "!unzip -q /content/final_dataset.zip -d /content/dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586008a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "from scipy.signal import butter, lfilter\n",
    "\n",
    "# 버터워스 대역 통과 필터 설계\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def apply_filter(data, lowcut=500, highcut=2000, fs=16000):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs)\n",
    "    return lfilter(b, a, data)\n",
    "\n",
    "def preprocess_all(base_path):\n",
    "    classes = ['class_0_noise', 'class_1_sneeze']\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "    sr = 16000\n",
    "    target_len = int(sr * 2.0)\n",
    "\n",
    "    for idx, cls in enumerate(classes):\n",
    "        path = os.path.join(base_path, cls)\n",
    "        files = [f for f in os.listdir(path) if f.endswith('.wav')]\n",
    "        print(f'{cls} 처리 중: {len(files)}개')\n",
    "\n",
    "        for f in files:\n",
    "            audio, _ = librosa.load(os.path.join(path, f), sr=sr)\n",
    "            audio = librosa.util.fix_length(audio, size=target_len)\n",
    "            \n",
    "            # 필터 적용 및 에너지 정규화\n",
    "            filtered = apply_filter(audio)\n",
    "            rms = np.sqrt(np.mean(filtered**2))\n",
    "            if rms > 0:\n",
    "                filtered = filtered / rms * 0.1\n",
    "                \n",
    "            mfcc = librosa.feature.mfcc(y=filtered, sr=sr, n_mfcc=20, hop_length=512)\n",
    "            X_data.append(mfcc)\n",
    "            y_data.append(idx)\n",
    "\n",
    "    np.save('X_filtered.npy', np.array(X_data))\n",
    "    np.save('y_filtered.npy', np.array(y_data))\n",
    "    print('X_filtered.npy 및 y_filtered.npy 저장 완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0e3530a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_0_noise 처리 중: 15120개\n",
      "class_1_sneeze 처리 중: 10080개\n",
      "X_filtered.npy 및 y_filtered.npy 저장 완료\n"
     ]
    }
   ],
   "source": [
    "preprocess_all('dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac4b28e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 67ms/step - accuracy: 0.6849 - loss: 0.5837 - val_accuracy: 0.7736 - val_loss: 0.4757\n",
      "Epoch 2/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.7752 - loss: 0.4832 - val_accuracy: 0.7815 - val_loss: 0.4643\n",
      "Epoch 3/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.8197 - loss: 0.4155 - val_accuracy: 0.8524 - val_loss: 0.3272\n",
      "Epoch 4/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.8578 - loss: 0.3408 - val_accuracy: 0.8795 - val_loss: 0.2845\n",
      "Epoch 5/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - accuracy: 0.8898 - loss: 0.2814 - val_accuracy: 0.8993 - val_loss: 0.2467\n",
      "Epoch 6/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 65ms/step - accuracy: 0.8991 - loss: 0.2504 - val_accuracy: 0.8996 - val_loss: 0.2459\n",
      "Epoch 7/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.9201 - loss: 0.2135 - val_accuracy: 0.9125 - val_loss: 0.2103\n",
      "Epoch 8/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 70ms/step - accuracy: 0.9268 - loss: 0.1981 - val_accuracy: 0.9219 - val_loss: 0.2017\n",
      "Epoch 9/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 70ms/step - accuracy: 0.9310 - loss: 0.1836 - val_accuracy: 0.9110 - val_loss: 0.2230\n",
      "Epoch 10/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 67ms/step - accuracy: 0.9375 - loss: 0.1690 - val_accuracy: 0.9273 - val_loss: 0.1872\n",
      "Epoch 11/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.9444 - loss: 0.1483 - val_accuracy: 0.9328 - val_loss: 0.1704\n",
      "Epoch 12/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9506 - loss: 0.1407 - val_accuracy: 0.9365 - val_loss: 0.1794\n",
      "Epoch 13/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 68ms/step - accuracy: 0.9581 - loss: 0.1214 - val_accuracy: 0.9380 - val_loss: 0.1730\n",
      "Epoch 14/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 72ms/step - accuracy: 0.9585 - loss: 0.1148 - val_accuracy: 0.9382 - val_loss: 0.1684\n",
      "Epoch 15/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 65ms/step - accuracy: 0.9652 - loss: 0.1006 - val_accuracy: 0.9395 - val_loss: 0.1631\n",
      "Epoch 16/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 66ms/step - accuracy: 0.9661 - loss: 0.0947 - val_accuracy: 0.9435 - val_loss: 0.1945\n",
      "Epoch 17/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 69ms/step - accuracy: 0.9720 - loss: 0.0784 - val_accuracy: 0.9402 - val_loss: 0.1841\n",
      "Epoch 19/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9758 - loss: 0.0723 - val_accuracy: 0.9340 - val_loss: 0.2065\n",
      "Epoch 20/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 74ms/step - accuracy: 0.9766 - loss: 0.0697 - val_accuracy: 0.9459 - val_loss: 0.2024\n",
      "Epoch 21/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 68ms/step - accuracy: 0.9798 - loss: 0.0614 - val_accuracy: 0.9430 - val_loss: 0.2160\n",
      "Epoch 22/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - accuracy: 0.9801 - loss: 0.0540 - val_accuracy: 0.9462 - val_loss: 0.2158\n",
      "Epoch 23/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 66ms/step - accuracy: 0.9835 - loss: 0.0466 - val_accuracy: 0.9432 - val_loss: 0.2259\n",
      "Epoch 24/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 70ms/step - accuracy: 0.9833 - loss: 0.0492 - val_accuracy: 0.9410 - val_loss: 0.2398\n",
      "Epoch 25/100\n",
      "\u001b[1m504/504\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 67ms/step - accuracy: 0.9842 - loss: 0.0431 - val_accuracy: 0.9469 - val_loss: 0.2204\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "# 데이터 로드\n",
    "X = np.load('X_filtered.npy')\n",
    "y = np.load('y_filtered.npy')\n",
    "\n",
    "# 차원 조정 (batch, time, freq, channel)\n",
    "X = X.transpose(0, 2, 1)\n",
    "X = X[..., np.newaxis]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 스케일러 적용 및 저장\n",
    "scaler = StandardScaler()\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_reshaped = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "scaler.fit(X_train_reshaped)\n",
    "joblib.dump(scaler, 'sneeze_scaler_filtered.pkl')\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train_reshaped).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test_reshaped).reshape(X_test.shape)\n",
    "\n",
    "# DS-CRNN 모델 정의\n",
    "def build_ds_crnn(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=input_shape),\n",
    "        layers.DepthwiseConv2D(kernel_size=(3, 3), padding='same', activation='relu'),\n",
    "        layers.Conv2D(32, (1, 1), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Reshape((input_shape[0]//2, -1)),\n",
    "        layers.GRU(64, return_sequences=False),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = build_ds_crnn(X_train_scaled.shape[1:])\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 학습\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, \n",
    "          validation_split=0.2, callbacks=[early_stop])\n",
    "\n",
    "model.save('sneeze_model_filtered.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1038de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp sneeze_model_filtered.keras /content/drive/MyDrive/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b50ef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp sneeze_scaler_filtered.pkl /content/drive/MyDrive/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
