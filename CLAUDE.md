# CLAUDE.md â€” AI Assistant Guide for sneezing_detection

This file provides context for AI assistants (Claude, Copilot, etc.) working in this repository.

---

## Project Overview

**sneezing_detection** is a real-time audio-based sneeze detection system built for embedded devices (Raspberry Pi, Jetson Nano). It combines a lightweight CNN trained on MFCC features with a modular Python pipeline for live microphone inference.

The project has two main components:
1. **Training** â€” Jupyter notebooks in `notebooks/` for experimenting with models and feature extraction
2. **Real-time Inference** â€” Production system in `realtime_detection/` that runs on-device

---

## Repository Structure

```
sneezing_detection/
â”œâ”€â”€ CLAUDE.md                          # This file
â”œâ”€â”€ README.md                          # Project overview and quick start
â”œâ”€â”€ .gitignore                         # Excludes models/, audio files, datasets
â”œâ”€â”€ legacy_code/                       # Old implementations (do not use)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ sneeze_synth_engine.py
â”‚   â”œâ”€â”€ test.py / test_filtered.py
â”‚   â”œâ”€â”€ train.ipynb / train_flitered.ipynb
â”‚   â””â”€â”€ sneeze_model_filtered.keras
â”œâ”€â”€ notebooks/                         # Jupyter training/research notebooks
â”‚   â”œâ”€â”€ sneeze_detection_lightweight.ipynb   # PRIMARY training notebook
â”‚   â”œâ”€â”€ sneeze_detection_feature_extraction.ipynb
â”‚   â”œâ”€â”€ Net_spectogram.ipynb
â”‚   â”œâ”€â”€ U-net.ipynb
â”‚   â”œâ”€â”€ YAMnet_fine_tuning.ipynb
â”‚   â””â”€â”€ YAMnet_from_none.ipynb
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ save_random_pickles.py         # Data utility for loading pickled datasets
â””â”€â”€ realtime_detection/                # PRODUCTION system
    â”œâ”€â”€ README.md                      # Detailed deployment guide
    â”œâ”€â”€ main.py                        # Entry point â€” RealtimeSneezeDetector
    â”œâ”€â”€ requirements.txt               # Production dependencies
    â”œâ”€â”€ detected_sneezes/              # Output dir (auto-created, tracked by .gitkeep)
    â”œâ”€â”€ modules/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ audio_capture.py           # Real-time mic input with circular buffer
    â”‚   â”œâ”€â”€ preprocessing.py           # RMS norm, pre-emphasis, silence trim
    â”‚   â”œâ”€â”€ mfcc_extractor.py          # MFCC + delta + delta-delta via librosa
    â”‚   â”œâ”€â”€ model_inference.py         # PyTorch model loading and inference
    â”‚   â””â”€â”€ output_handler.py          # Save audio clips, log CSV, cooldown logic
    â””â”€â”€ utils/
        â”œâ”€â”€ __init__.py
        â”œâ”€â”€ config.py                  # ALL configuration parameters (edit here)
        â””â”€â”€ model_definition.py        # LightweightSneezeCNN architecture
```

---

## Audio Processing Pipeline

```
Microphone (16 kHz)
    â†’ [1024-sample chunks via PyAudio callback]
Circular Buffer (4 s / 64000 samples)
    â†’ [2 s sliding window / 32000 samples]
Preprocessing (RMS norm=0.1, pre-emphasis=0.97, silence trim at 20 dB)
    â†’ [~10 ms]
MFCC Extraction (20 coefs + Î” + Î”Î” = 60 features, FFT=2048, hop=512)
    â†’ [~60â€“80 ms]
LightweightSneezeCNN inference
    â†’ [~15â€“25 ms]
Output Handler (threshold=0.95, cooldown=1.0 s, save WAV + CSV log)
```

Total latency: ~2.1 s (2 s window + ~100 ms processing)

---

## Model Architecture

**`LightweightSneezeCNN`** (defined in `utils/model_definition.py`):

- Input shape: `(batch, 1, 60, 63)` â€” MFCC with deltas, 2-second window
- 3Ã— Depthwise Separable Conv blocks (MobileNet-inspired): 1â†’32â†’64â†’128 channels
- Global Average Pooling â†’ FC(128) â†’ FC(64) â†’ FC(2)
- Output: `[not_sneeze_prob, sneeze_prob]`
- ~20,751 parameters, ~0.2 MB (FP32)

The trained model is saved at `models/best_model.pth` (excluded from git via `.gitignore`).

---

## Key Configuration â€” `realtime_detection/utils/config.py`

All tunable parameters live here. Do not hard-code values in modules.

| Section | Key Parameters |
|---|---|
| Audio | `SAMPLE_RATE=16000`, `CHUNK_SIZE=1024`, `WINDOW_SAMPLES=32000`, `BUFFER_SAMPLES=64000` |
| Preprocessing | `TARGET_RMS=0.1`, `PRE_EMPHASIS=0.97`, `TRIM_DB=20` |
| MFCC | `N_MFCC=20`, `N_FFT=2048`, `HOP_LENGTH=512`, `WINDOW='hann'`, include deltas |
| Model | `MODEL_PATH='../models/best_model.pth'`, `DEVICE='cpu'`, `THRESHOLD=0.95` |
| Output | `OUTPUT_DIR='detected_sneezes/'`, `LOG_CSV=True`, `COOLDOWN_SECONDS=1.0` |
| Performance | PyTorch threads limited to 2 (embedded-friendly) |

---

## Development Workflows

### Running Real-time Detection

```bash
cd realtime_detection
pip install -r requirements.txt
python main.py                          # Default config
python main.py --threshold 0.85         # Lower sensitivity
python main.py --model /path/to/model.pth --verbose
python main.py --quiet
```

### Testing Individual Modules

Each module is self-testable â€” run as a module from the `realtime_detection/` directory:

```bash
cd realtime_detection
python -m modules.audio_capture
python -m modules.preprocessing
python -m modules.mfcc_extractor
python -m modules.model_inference
python -m modules.output_handler
python -m utils.model_definition
```

### Training a New Model

Open and run `notebooks/sneeze_detection_lightweight.ipynb` (the primary training notebook). It handles:
- Dataset loading (ESC-50 for negatives, custom sneeze recordings for positives)
- Data augmentation (time stretch, pitch shift, noise addition)
- Training the `LightweightSneezeCNN`
- Saving `best_model.pth`

### Raspberry Pi Deployment

See `realtime_detection/README.md` for full instructions including systemd service setup.

---

## Code Conventions

### Module Pattern

Every module in `modules/` follows this structure:

```python
class XModule:
    def __init__(self, config):
        # Initialize from config
        pass

    def method(self, input):
        # Single responsibility
        pass

if __name__ == "__main__":
    # Self-test with dummy data
    pass
```

### Style Guidelines

- **Docstrings**: Google-style on all public classes and methods
- **Type hints**: Use where they aid clarity
- **Error handling**: `try/except` with descriptive messages; never silently swallow errors
- **Logging**: Print-based with emoji status indicators (`ğŸ¤ âœ“ âŒ ğŸ¤§`) â€” no external logging framework
- **Thread safety**: Use `threading.Lock()` when accessing the shared audio buffer
- **Configuration**: All parameters must come from `config.py`, never hard-coded in modules

### Naming Conventions

- Variables: `mfcc_features`, `sneeze_prob`, `audio_chunk` (descriptive snake_case)
- Classes: `PascalCase` (`AudioCaptureModule`, `LightweightSneezeCNN`)
- Constants in `config.py`: `UPPER_SNAKE_CASE`

---

## Dependencies

### Production (`realtime_detection/requirements.txt`)

| Library | Version | Purpose |
|---|---|---|
| `torch` | â‰¥2.0.0 | Model inference |
| `librosa` | â‰¥0.10.0 | MFCC extraction |
| `pyaudio` | â‰¥0.2.13 | Real-time mic capture |
| `numpy` | â‰¥1.24.0 | Array operations |
| `scipy` | â‰¥1.10.0 | Signal processing |
| `soundfile` | â‰¥0.12.1 | WAV file I/O |

System dependency: `portaudio19-dev` (required by PyAudio on Linux/RPi).

### Training (notebooks)

Additional: `pandas`, `matplotlib`, `scikit-learn`, `tensorflow`/`keras` (legacy notebooks), `jupyter`

---

## What to Avoid

- **Do not edit files in `legacy_code/`** â€” kept only for historical reference
- **Do not hard-code audio/model parameters** â€” all changes go through `config.py`
- **Do not commit model weights** (`*.pth`, `*.keras`, `*.h5`) â€” excluded by `.gitignore`
- **Do not commit audio datasets or recordings** â€” also excluded by `.gitignore`
- **Do not add GPU-specific code** without a CPU fallback â€” target hardware is CPU-only embedded devices
- **Do not increase PyTorch thread count** beyond what is in `config.py` on embedded targets

---

## Output Files

Detected sneezes are saved in `realtime_detection/detected_sneezes/`:

```
detected_sneezes/
â”œâ”€â”€ detection_log.csv          # Timestamp, filename, probability for every detection
â”œâ”€â”€ sneeze_20260221_143022.wav
â”œâ”€â”€ sneeze_20260221_143155.wav
â””â”€â”€ ...
```

The directory is tracked in git via `.gitkeep` but its contents are gitignored.

---

## Performance Targets

| Platform | CPU Usage | Memory | Latency |
|---|---|---|---|
| Desktop (x86) | 15â€“25% | ~60â€“80 MB | ~2.1 s |
| Raspberry Pi 4 | 25â€“40% | ~60â€“80 MB | ~2.1 s |

Inference threshold of 0.95 is deliberately high to minimize false positives (life noise from ESC-50 is used as the negative class).

---

## Project Metadata

- **Primary author**: Bahk Insung
- **AI collaborator**: Claude (Anthropic) via Claude Code CLI
- **Last updated**: February 2026
- **License**: Research/Educational
